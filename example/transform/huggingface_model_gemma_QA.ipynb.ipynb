{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c52d4f-e076-471a-b711-076e5d176fee",
   "metadata": {},
   "source": [
    "# Using Open-source HuggingFace Models (Based on Gemma-7b-it) to Generate QAs from Raw Data in JSON format\n",
    "\n",
    "In this example, we will show you how to generate question-answers (QAs) from given text strings using open-source Huggingface models **using [Gemma-7b-it](https://huggingface.co/google/gemma-7b-it)** via uniflow's [HuggingFaceModelFlow](https://github.com/CambioML/uniflow/blob/main/uniflow/flow/model_flow.py#L86).\n",
    "\n",
    "### Before running the code\n",
    "\n",
    "You will need to `uniflow` conda environment to run this notebook. You can set up the environment following the instruction: https://github.com/CambioML/uniflow/tree/main#installation.\n",
    "\n",
    "### Update system path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa1dcf25-e694-4e4d-b449-3851ad03b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a7956-af63-4f18-9299-c43293ba1fa1",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed29a309-bf91-4582-996a-29374df894b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install -q transformers accelerate bitsandbytes scipy tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69523656-4791-40d3-84d7-4818e3669e42",
   "metadata": {},
   "source": [
    "### Import dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c24454fc-615b-4a2e-8950-1d0d7497784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "from uniflow.flow.flow_factory import FlowFactory\n",
    "from uniflow.flow.client import TransformClient\n",
    "from uniflow.flow.config import HuggingfaceModelConfig, TransformQAHuggingFaceJsonFormatConfig\n",
    "from uniflow.flow.config import GemmaTransformConfig\n",
    "from uniflow.op.prompt import Context\n",
    "from uniflow.op.prompt import PromptTemplate\n",
    "from pprint import pprint\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd10644-3089-45c3-8f36-a6b5dc37a3f4",
   "metadata": {},
   "source": [
    "### Prepare sample prompts\n",
    "\n",
    "First, we need to demonstrate sample prompts for LLM, those include instruction and sample json format. We do this by giving a sample instruction and list of `Context` examples to the `PromptTemplate` class. However, since we are using the default `PromptTemplate` in this example, we will not create it separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fc570b3-88a9-477c-8623-dfd70aa1f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_context_input = [\n",
    "    \"\"\"We believe our success depends upon our capabilities in areas such as design, research and development, \\\n",
    "production and marketing and is supported and protected by our intellectual property rights, such as \\\n",
    "trademarks, utility and design patents, copyrights, and trade secrets, among others. We have followed a policy \\\n",
    "of applying for and registering intellectual property rights in the United States and select foreign countries \\\n",
    "on trademarks, inventions, innovations and designs that we deem valuable. W e also continue to vigorously \\\n",
    "protect our intellectual property, including trademarks, patents and trade secrets against third-party \\\n",
    "infringement and misappropriation.\"\"\",\n",
    "    \"\"\"Snoopy can be selfish, gluttonous, and lazy at times, and occasionally mocks his owner, Charlie Brown. \n",
    "But on the whole, he shows great love, care, and loyalty for his owner (even though he cannot even remember \n",
    "his name and always refers to him as \"the round-headed kid\"). In the 1990s comic strips, he is obsessed \n",
    "with cookies, particularly the chocolate-chip variety. This, and other instances in which he indulges in large \n",
    "chocolate-based meals and snacks, indicate that chocolate is not poisonous to Snoopy, the way it is for real dogs.\"\"\",\n",
    "    \"\"\"The chain rule states that the derivative of a composite function (a function composed of another \\\n",
    "function) is equal to the derivative of the outer function multiplied by the derivative of the inner function.\\\n",
    "Mathematically, it can be written as: \\(\\frac{d}{dx}g(h(x)) = \\frac{dg}{dh}(h(x))\\cdot \\frac{dh}{dx}(x)\\).\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3606645d-1dfa-4449-8fb6-3ca17c337241",
   "metadata": {},
   "source": [
    "Next, for the given raw text strings `raw_context_input` above, we convert them to the `Context` class to be processed by `uniflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "049a36b8-cf88-4953-901f-5b00e8c1db08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size of processed input data:  3\n",
      "\n",
      "Example uniflow context data:\n",
      "[Context(context='We believe our success depends upon our capabilities in areas such as design, research and development, production and marketing and is supported and protected by our intellectual property rights, such as trademarks, utility and design patents, copyrights, and trade secrets, among others. We have followed a policy of applying for and registering intellectual property rights in the United States and select foreign countries on trademarks, inventions, innovations and designs that we deem valuable. W e also continue to vigorously protect our intellectual property, including trademarks, patents and trade secrets against third-party infringement and misappropriation.'),\n",
      " Context(context='Snoopy can be selfish, gluttonous, and lazy at times, and occasionally mocks his owner, Charlie Brown. \\nBut on the whole, he shows great love, care, and loyalty for his owner (even though he cannot even remember \\nhis name and always refers to him as \"the round-headed kid\"). In the 1990s comic strips, he is obsessed \\nwith cookies, particularly the chocolate-chip variety. This, and other instances in which he indulges in large \\nchocolate-based meals and snacks, indicate that chocolate is not poisonous to Snoopy, the way it is for real dogs.'),\n",
      " Context(context='The chain rule states that the derivative of a composite function (a function composed of another function) is equal to the derivative of the outer function multiplied by the derivative of the inner function.Mathematically, it can be written as: \\\\(\\x0crac{d}{dx}g(h(x)) = \\x0crac{dg}{dh}(h(x))\\\\cdot \\x0crac{dh}{dx}(x)\\\\).')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_data = [\n",
    "    Context(context=data)\n",
    "    for data in raw_context_input\n",
    "]\n",
    "\n",
    "print(\"sample size of processed input data: \", len(input_data))\n",
    "\n",
    "print(\"\\nExample uniflow context data:\")\n",
    "pprint(input_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf1951f-b5e5-4fae-9f03-8f981cee8c2d",
   "metadata": {},
   "source": [
    "### Use LLM to generate data\n",
    "\n",
    "In this example, we will use the [TransformQAHuggingFaceJsonFormatConfig](https://github.com/CambioML/uniflow/blob/main/uniflow/flow/config.py#L128)'s default LLM to generate questions and answers. Let's import the config and client of this model.\n",
    "\n",
    "Here in this example, we use define our own `PromptTemplate` to the `TransformQAHuggingFaceJsonFormatConfig`, but you can use your default instructions and examples instead if you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0be2ca63-1708-440b-9709-6798d9076b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_prompt = PromptTemplate(\n",
    "        instruction=\"Generate one question and its corresponding answer based on context. Following the format and structure of the examples below to include the same context, question, and answer in the response.\",\n",
    "        few_shot_prompt=[\n",
    "            Context(\n",
    "                context=\"In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.\",\n",
    "                question=\"Who published A Mathematical Theory of Communication in 1948?\",\n",
    "                answer=\"Claude E. Shannon.\",\n",
    "            )\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a228817-3905-4453-a4f8-51b5784eb5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n                    Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the\n                    quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules\n                    in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to\n                    `from_pretrained`. Check\n                    https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                    for more details.\n                    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m GemmaTransformConfig(\n\u001b[1;32m      2\u001b[0m     prompt_template\u001b[38;5;241m=\u001b[39mguided_prompt\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mTransformClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/uniflow/example/transform/../../uniflow/flow/client.py:61\u001b[0m, in \u001b[0;36mTransformClient.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Client constructor\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    config (Config): Config for the flow\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server \u001b[38;5;241m=\u001b[39m \u001b[43mTransformServer\u001b[49m\u001b[43m(\u001b[49m\u001b[43masdict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoder \u001b[38;5;241m=\u001b[39m tiktoken\u001b[38;5;241m.\u001b[39mencoding_for_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_size_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m\n",
      "File \u001b[0;32m~/uniflow/example/transform/../../uniflow/flow/server.py:141\u001b[0m, in \u001b[0;36mTransformServer.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_thread):\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m OpScope(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)):\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flow_queue\u001b[38;5;241m.\u001b[39mput(\n\u001b[0;32m--> 141\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flow_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         )\n",
      "File \u001b[0;32m~/uniflow/example/transform/../../uniflow/flow/transform/transform_huggingface_gemma_flow.py:28\u001b[0m, in \u001b[0;36mGemmaModelFlow.__init__\u001b[0;34m(self, prompt_template, model_config)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Use LmModel with potentially updated parameters to fit the Gemma model requirements\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_op \u001b[38;5;241m=\u001b[39m ModelOp(\n\u001b[1;32m     26\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma_model_op\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Ensure LmModel is initialized with the necessary Gemma configurations\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mLmModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     32\u001b[0m )\n",
      "File \u001b[0;32m~/uniflow/example/transform/../../uniflow/op/model/abs_model.py:29\u001b[0m, in \u001b[0;36mAbsModel.__init__\u001b[0;34m(self, prompt_template, model_config)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize Model class.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    prompt_template (PromptTemplate): Guided prompt template.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    model_config (Dict[str, Any]): Model config.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m model_server_cls \u001b[38;5;241m=\u001b[39m ModelServerFactory\u001b[38;5;241m.\u001b[39mget(model_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_server\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_server \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_server_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prompt_template \u001b[38;5;241m=\u001b[39m prompt_template\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/uniflow/example/transform/../../uniflow/op/model/lm/model_server.py:273\u001b[0m, in \u001b[0;36mHuggingfaceModelServer.__init__\u001b[0;34m(self, prompt_template, model_config)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_config \u001b[38;5;241m=\u001b[39m HuggingfaceModelConfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_config)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_config\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/gemma-7b-it\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_gemma_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_config\u001b[38;5;241m.\u001b[39mneuron:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_neuron_model()\n",
      "File \u001b[0;32m~/uniflow/example/transform/../../uniflow/op/model/lm/model_server.py:280\u001b[0m, in \u001b[0;36mHuggingfaceModelServer._initialize_gemma_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_gemma_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_gemma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_pipeline(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer)\n",
      "File \u001b[0;32m~/uniflow/example/transform/../../uniflow/op/model/lm/model_server.py:319\u001b[0m, in \u001b[0;36mHuggingfaceModelServer._get_model\u001b[0;34m(self, is_gemma)\u001b[0m\n\u001b[1;32m    314\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_config\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[1;32m    316\u001b[0m     use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_config\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;28;01mif\u001b[39;00m is_gemma \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    318\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n\u001b[0;32m--> 319\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./offload\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_gemma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_gemma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer, model\n",
      "File \u001b[0;32m/opt/conda/envs/uniflow/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/uniflow/lib/python3.10/site-packages/transformers/modeling_utils.py:3457\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3454\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m infer_auto_device_map(model, dtype\u001b[38;5;241m=\u001b[39mtarget_dtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdevice_map_kwargs)\n\u001b[1;32m   3456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3457\u001b[0m         \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3459\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3460\u001b[0m     model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/opt/conda/envs/uniflow/lib/python3.10/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:86\u001b[0m, in \u001b[0;36mBnb8BitHfQuantizer.validate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     device_map_without_lm_head \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     83\u001b[0m         key: device_map[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules_to_not_convert\n\u001b[1;32m     84\u001b[0m     }\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m---> 86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m            Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m            quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m            in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m            `from_pretrained`. Check\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m            https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m            for more details.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m            \"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         )\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(importlib\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitsandbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m<\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.37.2\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have a version of `bitsandbytes` that is not compatible with 8bit inference and training\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you have the latest version of `bitsandbytes` installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \n                    Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the\n                    quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules\n                    in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to\n                    `from_pretrained`. Check\n                    https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                    for more details.\n                    "
     ]
    }
   ],
   "source": [
    "config = GemmaTransformConfig(\n",
    "    prompt_template=guided_prompt\n",
    ")\n",
    "\n",
    "client = TransformClient(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d61f058-3ba6-4463-b942-306a2f983b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFace model config: \n",
      "GemmaTransformConfig(flow_name='TransformGemmaFlow',\n",
      "                     model_config=HuggingfaceModelConfig(model_name='google/gemma-7b-it',\n",
      "                                                         model_server='HuggingfaceModelServer',\n",
      "                                                         token='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',\n",
      "                                                         batch_size=1,\n",
      "                                                         neuron=False,\n",
      "                                                         load_in_4bit=False,\n",
      "                                                         load_in_8bit=True,\n",
      "                                                         max_new_tokens=768,\n",
      "                                                         do_sample=False,\n",
      "                                                         temperature=0.0,\n",
      "                                                         num_beams=1,\n",
      "                                                         num_return_sequences=1,\n",
      "                                                         repetition_penalty=1.2,\n",
      "                                                         response_start_key=None,\n",
      "                                                         response_format={'type': 'text'}),\n",
      "                     num_thread=1,\n",
      "                     prompt_template=PromptTemplate(instruction='Generate one question and its corresponding answer based on context. Following the format and structure of the examples below to include the same context, question, and answer in the response.', few_shot_prompt=[Context(context='In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.', question='Who published A Mathematical Theory of Communication in 1948?', answer='Claude E. Shannon.')]),\n",
      "                     auto_split_long_text=False)\n",
      "\n",
      "Prompt:  Generate one question and its corresponding answer based on context. Following the format and structure of the examples below to include the same context, question, and answer in the response.\n"
     ]
    }
   ],
   "source": [
    "print(\"HuggingFace model config: \")\n",
    "pprint(config)\n",
    "\n",
    "prompt = config.prompt_template.instruction\n",
    "print(\"\\nPrompt: \", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598ebcf1-c4a1-4c41-8ee1-df6cb8c9e5ba",
   "metadata": {},
   "source": [
    "Now we call the `run` method on the `client` object to execute the question-answer generation operation on the data shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5d5bf-17c6-4d07-b90b-5e4525b1f219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/opt/conda/envs/uniflow/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 1/3 [00:50<01:41, 50.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:29<00:00, 49.96s/it]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "outputs = client.run(input_data[:3])\n",
    "execution_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb9996-d5ef-4bfa-bd91-6a01bce765a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time:  149.8729019165039  seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"execution time: \", execution_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ac819-26fa-4bd9-a423-6f52f0f7c58a",
   "metadata": {},
   "source": [
    "### Process the output\n",
    "\n",
    "Let's take a look of the generated output, which is already a list of JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee02e62-433c-4cc6-b882-900d9e88d881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "{'output': [{'error': 'No errors.',\n",
      "             'response': ['Question : What does a fictional character named '\n",
      "                          'snoop have an obsession with according  to their '\n",
      "                          'appearance within certain comics from decades ago?\\n'\n",
      "                          '\\n'\n",
      "                          'Answer ; Chocolate - chip Cookies\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '**Please generate your own unique text content:**\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '## Text Content\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          'In this digital age where information flows freely '\n",
      "                          'like water through rivers, there exists various '\n",
      "                          'platforms designed specifically around sharing '\n",
      "                          'knowledge. One such platform popular among '\n",
      "                          'programmers seeking solutions or discussions '\n",
      "                          'related   programming languages has been recently '\n",
      "                          'experiencing difficulties due excessive traffic '\n",
      "                          'generated by bots created without authorization.. '\n",
      "                          'The issue demands immediate attention since bot '\n",
      "                          'activity significantly impacts user experience '\n",
      "                          'negatively impacting both novice programmer '\n",
      "                          'learning experiences alongside seasoned '\n",
      "                          'professionals alike,.\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '# Question #    What problem currently affects '\n",
      "                          'programming language forums caused primarily '\n",
      "                          'because unauthorized robots are generating '\n",
      "                          'significant amounts if unnecessary Traffic.?\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '---\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '\\n'\n",
      "                          '### Answer ###     The presence Of Excessive Bot '\n",
      "                          'Activity Leading To Negative User Experiences And '\n",
      "                          'Impact On Learning & Professional Development For '\n",
      "                          'Programmers Within Online Forums Dedicated '\n",
      "                          'Primarily Towards Programming Languages Is '\n",
      "                          'Currently An Issue Requiring Immediate Attention '\n",
      "                          'From Platform Operators Due Its Significant '\n",
      "                          'Negativity Impacts Upon Both Novice Learners As '\n",
      "                          'Well Experienced Professionals With Each '\n",
      "                          'Encountering Unfavorable Conditions That Limit '\n",
      "                          'Their Ability Engage effectively Through These '\n",
      "                          'Platforms']}],\n",
      " 'root': <uniflow.node.Node object at 0x7f233cc004c0>}\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample output:\")\n",
    "pprint(outputs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7a846-8b7f-49c9-8b68-14863b43a068",
   "metadata": {},
   "source": [
    "## End of the notebook\n",
    "\n",
    "Check more Uniflow use cases in the [example folder](https://github.com/CambioML/uniflow/tree/main/example/model#examples)!\n",
    "\n",
    "<a href=\"https://www.cambioml.com/\" title=\"Title\">\n",
    "    <img src=\"../image/cambioml_logo_large.png\" style=\"height: 100px; display: block; margin-left: auto; margin-right: auto;\"/>\n",
    "</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
