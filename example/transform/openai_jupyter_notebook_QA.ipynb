{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cbc4c4a",
   "metadata": {},
   "source": [
    "# Generating QAs from a Jupyter Notebook\n",
    "\n",
    "In this example, we will show you how to generate question-answer pairs from a given jupyter notebook.\n",
    "\n",
    "### Before running the code\n",
    "\n",
    "You will need to `uniflow` conda environment to run this notebook. You can set up the environment following the instruction: https://github.com/CambioML/uniflow/tree/main#installation.\n",
    "\n",
    "Next, you will need a valid [OpenAI API key](https://platform.openai.com/api-keys) to run the code. Once you have the key, set it as the environment variable `OPENAI_API_KEY` within a `.env` file in the root directory of this repository. For more details, see this [instruction](https://github.com/CambioML/uniflow/tree/main#api-keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093be070",
   "metadata": {},
   "source": [
    "### Import dependency\n",
    "First, we set system paths and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d84dd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "from uniflow.flow.client import TransformClient\n",
    "from uniflow.flow.config import TransformOpenAIConfig\n",
    "from uniflow.op.model.model_config import OpenAIModelConfig\n",
    "from uniflow.op.prompt import Context, PromptTemplate\n",
    "\n",
    "from langchain.document_loaders import NotebookLoader\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e2d4d",
   "metadata": {},
   "source": [
    "### Prepare the input data\n",
    "First, we need to pre-process the given jupyter notebook `model.ipynb` to get text chunks that we can feed into the model. We will use `NotebookLoader` from langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092b355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_cur = os.getcwd()\n",
    "jupyter_notebook_file = \"model.ipynb\"\n",
    "input_file = os.path.join(f\"{dir_cur}\", jupyter_notebook_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\uniflow\\lib\\site-packages\\langchain_community\\document_loaders\\notebook.py:122: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  filtered_data = filtered_data.applymap(remove_newlines)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\'markdown\\' cell: \\'[\\'# Notebook for ModelFlow \\', \\'\\', \"In this example, we will show you how to generate question-answers (QAs) from give text strings using OpenAI\\'s models via uniflow\\'s [ModelFlow](https://github.com/CambioML/uniflow/blob/main/uniflow/flow/model_flow.py#L11).\", \\'\\', \\'### Before running the code\\', \\'\\', \\'You will need to `uniflow` conda environment to run this notebook. You can set up the environment following the instruction: https://github.com/CambioML/uniflow/tree/main#installation.\\', \\'\\', \\'Next, you will need a valid [OpenAI API key](https://platform.openai.com/api-keys) to run the code. Once you have the key, set it as the environment variable `OPENAI_API_KEY` within a `.env` file in the root directory of this repository. For more details, see this [instruction](https://github.com/CambioML/uniflow/tree/main#api-keys)\\', \\'\\', \\'### Update system path\\']\\'\\n\\n \\'code\\' cell: \\'[\\'%reload_ext autoreload\\', \\'%autoreload 2\\', \\'\\', \\'import sys\\', \\'\\', \\'sys.path.append(\".\")\\', \\'sys.path.append(\"..\")\\', \\'sys.path.append(\"../..\")\\']\\'\\n\\n \\'markdown\\' cell: \\'[\\'## Import dependency\\']\\'\\n\\n  \\'markdown\\' cell: \\'[\\'### Display the different flows\\']\\'\\n\\n  \\'markdown\\' cell: \\'[\\'### Prepare Sample Prompts\\', \\'Here, we will use the following sample prompts from which to generate QAs.\\']\\'\\n\\n \\'code\\' cell: \\'[\\'raw_context_input = [\\', \\'    \"It was a sunny day and the sky color is blue.\",\\', \\'    \"My name is Bobby and I am a talent software engineer working on AI/ML\",\\', \\']\\']\\'\\n\\n \\'markdown\\' cell: \\'[\\'Next, for the given raw text strings `raw_context_input` above, we convert them to the `Context` class to be processed by `uniflow`.\\']\\'\\n\\n \\'code\\' cell: \\'[\\'\\', \\'data = [\\', \\'    Context(context=c)\\', \\'    for c in raw_context_input\\', \\']\\']\\'\\n\\n \\'markdown\\' cell: \\'[\\'### Use LLM to generate data\\', \\'In this example, we use the base `Config` defaults with the [OpenAIModelConfig](https://github.com/CambioML/uniflow/blob/main/uniflow/model/config.py#L17) to generate questions and answers.\\']\\'\\n\\n \\'code\\' cell: \\'[\\'config = TransformConfig(\\', \\'    flow_name=\"TransformOpenAIFlow\",\\', \\'    model_config=OpenAIModelConfig()\\', \\')\\', \\'client = TransformClient(config)\\']\\'\\n\\n \\'markdown\\' cell: \\'[\\'Now we call the `run` method on the `client` object to execute the question-answer generation operation on the data shown above.\\']\\'\\n\\n \\'code\\' cell: \\'[\\'output = client.run(data)\\', \\'output\\']\\'\\n with output: \\'[\\'100%|██████████| 2/2 [00:03<00:00,  1.74s/it]\\\\n\\']\\'\\n\\n \\'markdown\\' cell: \\'[\\'### View the output\\', \\'\\', \"Let\\'s take a look of the generated output.\"]\\'\\n\\n  \\'markdown\\' cell: \\'[\\'### Plot model flow graph\\', \\'Here, we visualize the model flow graph for the `ModelFlow`.\\']\\'\\n\\n \\'code\\' cell: \\'[\"graph = Viz.to_digraph(output[0][\\'root\\'])\"]\\'\\n\\n  \\'code\\' cell: \\'[\"graph = Viz.to_digraph(output[1][\\'root\\'])\"]\\'\\n\\n '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = NotebookLoader(input_file,\n",
    "                        include_outputs=True,\n",
    "                        max_output_length=1000,\n",
    "                        remove_newline=True)\n",
    "raw_content = loader.load()\n",
    "raw_content[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the loaded jupyter notebook content is quite messy. Let's split this content by each markdown header!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string_based_on_markdown_header(s, markdown_symbol, code_symbol):\n",
    "    \"\"\"\n",
    "    Splits a string based on a list of tokens including markdown_symbol and code_symbol,\n",
    "    then further process the list so that the given string s is splits based on each markdown header.\n",
    "\n",
    "    :param s: The string to be split.\n",
    "    :param markdown_symbol: A symbol that represented a markdown cell.\n",
    "    :param code_symbol: A symbol that represented a code cell.\n",
    "    :return: A list of strings, split based markdown header.\n",
    "    \"\"\"\n",
    "    # Create a regular expression pattern from the tokens, ensuring to escape special characters\n",
    "    pattern = '|'.join(re.escape(token) for token in [markdown_symbol, code_symbol])\n",
    "\n",
    "    # Use re.split() to split the string, but keep the tokens in the result\n",
    "    strings = re.split(f'(?={pattern})', s)\n",
    "\n",
    "    # Further process the list\n",
    "    processed = []\n",
    "    for s in strings:\n",
    "        # Check if the string starts with \"'markdown' cell: '\"\n",
    "        if s.startswith(markdown_symbol):\n",
    "            # Split the string by the specified pattern ', '\n",
    "            parts = re.split(\"\"\"', '\"\"\" , s)\n",
    "\n",
    "            # Process each part\n",
    "            new_list = []\n",
    "            for part in parts:\n",
    "                # If the part starts with \"#\", \"##\", or \"###\", it remains standalone\n",
    "                if part.startswith(\"#\") or part.startswith(\"##\") or part.startswith(\"###\"):\n",
    "                    new_list.append(part)\n",
    "                # Otherwise, it is appended to the previous part\n",
    "                else:\n",
    "                    if new_list:\n",
    "                        new_list[-1] += \"\\n\"\n",
    "                        new_list[-1] += part\n",
    "                    else:\n",
    "                        # If it's the first part and doesn't start with \"#\", it's added as is\n",
    "                        new_list.append(part)\n",
    "\n",
    "            # Add the processed parts to the main list\n",
    "            processed.extend(new_list)\n",
    "\n",
    "        # For strings starting with \"\"\"'code' cell\"\"\", append them to the last string\n",
    "        elif s.startswith(code_symbol):\n",
    "            processed[-1] += s\n",
    "        else:\n",
    "            # Remove empty lines\n",
    "            if len(s.replace(\"\\n\", \"\")) > 0:\n",
    "                processed.append(s)\n",
    "\n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the `split_string_based_on_markdown_header` function, let's split our loaded jupyter notebook! It's much more semanticly organized now as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= New Header ================\n",
      "'markdown' cell: '['# Notebook for ModelFlow \n",
      "', \"In this example, we will show you how to generate question-answers (QAs) from give text strings using OpenAI's models via uniflow's [ModelFlow](https://github.com/CambioML/uniflow/blob/main/uniflow/flow/model_flow.py#L11).\", '\n",
      "================= New Header ================\n",
      "### Before running the code\n",
      "\n",
      "You will need to `uniflow` conda environment to run this notebook. You can set up the environment following the instruction: https://github.com/CambioML/uniflow/tree/main#installation.\n",
      "\n",
      "Next, you will need a valid [OpenAI API key](https://platform.openai.com/api-keys) to run the code. Once you have the key, set it as the environment variable `OPENAI_API_KEY` within a `.env` file in the root directory of this repository. For more details, see this [instruction](https://github.com/CambioML/uniflow/tree/main#api-keys)\n",
      "\n",
      "================= New Header ================\n",
      "### Update system path']'\n",
      "\n",
      " 'code' cell: '['%reload_ext autoreload', '%autoreload 2', '', 'import sys', '', 'sys.path.append(\".\")', 'sys.path.append(\"..\")', 'sys.path.append(\"../..\")']'\n",
      "\n",
      " \n",
      "================= New Header ================\n",
      "'markdown' cell: '['## Import dependency']'\n",
      "\n",
      "  \n",
      "================= New Header ================\n",
      "'markdown' cell: '['### Display the different flows']'\n",
      "\n",
      "  \n",
      "================= New Header ================\n",
      "'markdown' cell: '['### Prepare Sample Prompts\n",
      "Here, we will use the following sample prompts from which to generate QAs.']'\n",
      "\n",
      " 'code' cell: '['raw_context_input = [', '    \"It was a sunny day and the sky color is blue.\",', '    \"My name is Bobby and I am a talent software engineer working on AI/ML\",', ']']'\n",
      "\n",
      " \n",
      "================= New Header ================\n",
      "'markdown' cell: '['Next, for the given raw text strings `raw_context_input` above, we convert them to the `Context` class to be processed by `uniflow`.']'\n",
      "\n",
      " 'code' cell: '['', 'data = [', '    Context(context=c)', '    for c in raw_context_input', ']']'\n",
      "\n",
      " \n",
      "================= New Header ================\n",
      "'markdown' cell: '['### Use LLM to generate data\n",
      "In this example, we use the base `Config` defaults with the [OpenAIModelConfig](https://github.com/CambioML/uniflow/blob/main/uniflow/model/config.py#L17) to generate questions and answers.']'\n",
      "\n",
      " 'code' cell: '['config = TransformConfig(', '    flow_name=\"TransformOpenAIFlow\",', '    model_config=OpenAIModelConfig()', ')', 'client = TransformClient(config)']'\n",
      "\n",
      " \n",
      "================= New Header ================\n",
      "'markdown' cell: '['Now we call the `run` method on the `client` object to execute the question-answer generation operation on the data shown above.']'\n",
      "\n",
      " 'code' cell: '['output = client.run(data)', 'output']'\n",
      " with output: '['100%|██████████| 2/2 [00:03<00:00,  1.74s/it]\\n']'\n",
      "\n",
      " \n",
      "================= New Header ================\n",
      "'markdown' cell: '['### View the output\n",
      "', \"Let's take a look of the generated output.\"]'\n",
      "\n",
      "  \n",
      "================= New Header ================\n",
      "'markdown' cell: '['### Plot model flow graph\n",
      "Here, we visualize the model flow graph for the `ModelFlow`.']'\n",
      "\n",
      " 'code' cell: '[\"graph = Viz.to_digraph(output[0]['root'])\"]'\n",
      "\n",
      "  'code' cell: '[\"graph = Viz.to_digraph(output[1]['root'])\"]'\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "markdown_symbol = \"\"\"\\'markdown\\' cell: \\'\"\"\"\n",
    "code_symbol = \"\"\"\\'code\\' cell: \\'\"\"\"\n",
    "content_splited_by_header =  split_string_based_on_markdown_header(raw_content[0].page_content,\n",
    "                                               markdown_symbol=markdown_symbol,\n",
    "                                               code_symbol=code_symbol)\n",
    "for j in content_splited_by_header:\n",
    "    print(\"================= New Header ================\")\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Uniflow on the self-instruct dataset (with prompt)\n",
    "\n",
    "Now we can extract knowledge from the given jupyter notebook via Uniflow! First, we need to define a [PromptTemplate](https://github.com/CambioML/uniflow/blob/main/uniflow/schema.py#L57), which includes a prompt and a list of examples for the LLM to do few-shot learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_prompt = PromptTemplate(\n",
    "    instruction=\"If there is a code cell, generate one question given the markdown cell and its corresponding \\\n",
    "answer based on code cell and its output. If there is no code cell, generate one question and its corresponding \\\n",
    "answer based on context. Following the format of the examples below to include the same context, question, and \\\n",
    "answer in the response.\",\n",
    "    few_shot_prompt=[\n",
    "        Context(\n",
    "            context=\"\"\"'markdown' cell: '['### Use LLM to generate data in Uniflow.\n",
    "            In this example, we use the base `Config` defaults with the [OpenAIModelConfig] to generate questions and answers.']'\n",
    "            'code' cell: '['config = Config(model_config=OpenAIModelConfig())', 'client = Client(config)']'\"\"\",\n",
    "            question=\"How to use LLM to generate data in Uniflow\",\n",
    "            answer=\"We can use the Uniflow's default [OpenAIModelConfig] to generate questions and answers with code: '['config = Config(model_config=OpenAIModelConfig())', 'client = Client(config)']'\",\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e89b3",
   "metadata": {},
   "source": [
    "In this example, we will use the [`OpenAIModelConfig`](https://github.com/CambioML/uniflow/blob/main/uniflow/model/config.py#L17) as the default LLM to generate questions and answers. If you want to use open-source models, you can replace the `OpenAIConfig` and `OpenAIModelConfig` with `HuggingfaceConfig` and [`HuggingfaceModelConfig`](https://github.com/CambioML/uniflow/blob/main/uniflow/model/config.py#L27).\n",
    "\n",
    "Now we pass in our `guided_prompt` to the `OpenAIConfig` to use our customized instructions and examples, instead of the `uniflow` default ones. \n",
    "\n",
    "We also want to get the response in the `json` format instead of the `text` default, so we set the `response_format` to `json_object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TransformOpenAIConfig(\n",
    "    prompt_template=guided_prompt,\n",
    "    model_config=OpenAIModelConfig(response_format={\"type\": \"json_object\"}),\n",
    ")\n",
    "client = TransformClient(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbeb79ac",
   "metadata": {},
   "source": [
    "Since each example in the `guided_prompt` are wrapped by `Context`, we need to apply the same format on our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee4a54152784706b9abdfab3ee0298a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [Context(context=p) for p in content_splited_by_header if len(p) > 10]\n",
    "output = client.run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'output': [{'response': [{'error': 'No code cell found'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x24aef2c3970>},\n",
       " {'output': [{'response': [{'response': [{'context': \"'markdown' cell: '['### Use LLM to generate data in Uniflow.\\n            In this example, we use the base `Config` defaults with the [OpenAIModelConfig] to generate questions and answers.']'\\n            'code' cell: '['config = Config(model_config=OpenAIModelConfig())', 'client = Client(config)']'\",\n",
       "        'question': 'How to use LLM to generate data in Uniflow',\n",
       "        'answer': \"We can use the Uniflow's default [OpenAIModelConfig] to generate questions and answers with code: '['config = Config(model_config=OpenAIModelConfig())', 'client = Client(config)']'\"},\n",
       "       {'context': '### Before running the code\\n\\nYou will need to `uniflow` conda environment to run this notebook. You can set up the environment following the instruction: https://github.com/CambioML/uniflow/tree/main#installation.\\n\\nNext, you will need a valid [OpenAI API key](https://platform.openai.com/api-keys) to run the code. Once you have the key, set it as the environment variable `OPENAI_API_KEY` within a `.env` file in the root directory of this repository. For more details, see this [instruction](https://github.com/CambioML/uniflow/tree/main#api-keys)\\n',\n",
       "        'question': 'What are the requirements for running the code?',\n",
       "        'answer': 'To run the code, you will need to have the `uniflow` conda environment set up and a valid [OpenAI API key] set as an environment variable `OPENAI_API_KEY` within a `.env` file in the root directory of the repository.'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x24aef2ec040>},\n",
       " {'output': [{'response': [{'error': 'No code cell found'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x24aef2edc00>},\n",
       " {'output': [{'response': [{'error': 'No code cell found'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x24aef2edcc0>},\n",
       " {'output': [{'response': [{'error': 'No code cell found'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x24aef2edd80>},\n",
       " {'output': [{'response': [{'context': \"'markdown' cell: '['### Use LLM to generate data in Uniflow.\\n            In this example, we use the base `Config` defaults with the [OpenAIModelConfig] to generate questions and answers.']'\\n            'code' cell: '['config = Config(model_config=OpenAIModelConfig())', 'client = Client(config)']'\",\n",
       "      'question': 'How to use LLM to generate data in Uniflow',\n",
       "      'answer': \"We can use the Uniflow's default [OpenAIModelConfig] to generate questions and answers with code: '['config = Config(model_config=OpenAIModelConfig())', 'client = Client(config)']'\"}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x24aef2ede40>},\n",
       " {'output': [{'response': [{'context': \"'markdown' cell: '['Next, for the given raw text strings `raw_context_input` above, we convert them to the `Context` class to be processed by `uniflow`.']'\\n\\n 'code' cell: '['', 'data = [', '    Context(context=c)', '    for c in raw_context_input', ']']'\",\n",
       "      'question': 'How do we convert the raw text strings to the Context class for processing by uniflow?',\n",
       "      'answer': \"We can convert the raw text strings to the Context class for processing by uniflow using the following code: '['', 'data = [', '    Context(context=c)', '    for c in raw_context_input', ']']'\"}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x24aef2edf00>},\n",
       " {'output': [{'response': [{'question': 'How to use LLM to generate data',\n",
       "      'answer': 'To use LLM to generate data, we can use the base `Config` defaults with the [OpenAIModelConfig](https://github.com/CambioML/uniflow/blob/main/uniflow/model/config.py#L17) and initialize the client with code: \\'[\\'config = TransformConfig(\\', \\'    flow_name=\"TransformOpenAIFlow\",\\', \\'    model_config=OpenAIModelConfig()\\', \\')\\', \\'client = TransformClient(config)\\']\\''}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x24aef2edfc0>},\n",
       " {'output': [{'response': [{'question': \"How do we execute the question-answer generation operation on the data using the 'client' object?\",\n",
       "      'answer': \"We can call the 'run' method on the 'client' object with code: '['output = client.run(data)', 'output']'\"}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x24aef2ee080>},\n",
       " {'output': [{'response': [{'error': 'No code cell found to generate a question and answer pair based on the given context.'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x24aef2ee140>},\n",
       " {'output': [{'response': [{'response': [{'context': \"'markdown' cell: '['### Use LLM to generate data in Uniflow.\\n            In this example, we use the base `Config` defaults with the [OpenAIModelConfig] to generate questions and answers.']'\\n            'code' cell: '['config = Config(model_config=OpenAIModelConfig())', 'client = Client(config)']'\",\n",
       "        'question': 'How to use LLM to generate data in Uniflow',\n",
       "        'answer': \"We can use the Uniflow's default [OpenAIModelConfig] to generate questions and answers with code: '['config = Config(model_config=OpenAIModelConfig())', 'client = Client(config)']'\"},\n",
       "       {'context': '\\'markdown\\' cell: \\'[\\'### Plot model flow graph\\nHere, we visualize the model flow graph for the `ModelFlow`.\\']\\'\\n\\n \\'code\\' cell: \\'[\"graph = Viz.to_digraph(output[0][\\'root\\'])\"]\\'\\n\\n  \\'code\\' cell: \\'[\"graph = Viz.to_digraph(output[1][\\'root\\'])\"]\\'\\n\\n',\n",
       "        'question': 'How can we visualize the model flow graph for ModelFlow?',\n",
       "        'answer': 'The model flow graph for ModelFlow can be visualized using the code: \\'[\"graph = Viz.to_digraph(output[0][\\'root\\'])\"]\\''}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x24aef2ee200>}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat the output into pandas table\n",
    "\n",
    "The output is a bit messy, we can reconstructure it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d7a120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e9566 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e9566_row0_col0, #T_e9566_row0_col1, #T_e9566_row0_col2, #T_e9566_row1_col0, #T_e9566_row1_col1, #T_e9566_row1_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e9566\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e9566_level0_col0\" class=\"col_heading level0 col0\" >context</th>\n",
       "      <th id=\"T_e9566_level0_col1\" class=\"col_heading level0 col1\" >question</th>\n",
       "      <th id=\"T_e9566_level0_col2\" class=\"col_heading level0 col2\" >answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e9566_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e9566_row0_col0\" class=\"data row0 col0\" >'markdown' cell: '['### Use LLM to generate data in Uniflow.\n",
       "            In this example, we use the base `Config` defaults with the [OpenAIModelConfig] to generate questions and answers.']'\n",
       "            'code' cell: '['config = Config(model_config=OpenAIModelConfig())', 'client = Client(config)']'</td>\n",
       "      <td id=\"T_e9566_row0_col1\" class=\"data row0 col1\" >How to use LLM to generate data in Uniflow</td>\n",
       "      <td id=\"T_e9566_row0_col2\" class=\"data row0 col2\" >We can use the Uniflow's default [OpenAIModelConfig] to generate questions and answers with code: '['config = Config(model_config=OpenAIModelConfig())', 'client = Client(config)']'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9566_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e9566_row1_col0\" class=\"data row1 col0\" >'markdown' cell: '['Next, for the given raw text strings `raw_context_input` above, we convert them to the `Context` class to be processed by `uniflow`.']'\n",
       "\n",
       " 'code' cell: '['', 'data = [', '    Context(context=c)', '    for c in raw_context_input', ']']'</td>\n",
       "      <td id=\"T_e9566_row1_col1\" class=\"data row1 col1\" >How do we convert the raw text strings to the Context class for processing by uniflow?</td>\n",
       "      <td id=\"T_e9566_row1_col2\" class=\"data row1 col2\" >We can convert the raw text strings to the Context class for processing by uniflow using the following code: '['', 'data = [', '    Context(context=c)', '    for c in raw_context_input', ']']'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24aeec53b80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df = pd.DataFrame([{'context': response['context'],\n",
    "                    'question': response['question'],\n",
    "                    'answer': response['answer']}\n",
    "                   for item in output\n",
    "                   for i in item['output']\n",
    "                   for response in i['response'] if 'context' in response])\n",
    "\n",
    "styled_df = df.style.set_properties(**{'text-align': 'left'}).set_table_styles([{\n",
    "    'selector': 'th',\n",
    "    'props': [('text-align', 'left')]\n",
    "}])\n",
    "styled_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26797da6",
   "metadata": {},
   "source": [
    "## End of the notebook\n",
    "\n",
    "Check more Uniflow use cases in the [example folder](https://github.com/CambioML/uniflow/tree/main/example/model#examples)!\n",
    "\n",
    "<a href=\"https://www.cambioml.com/\" title=\"Title\">\n",
    "    <img src=\"../image/cambioml_logo_large.png\" style=\"height: 100px; display: block; margin-left: auto; margin-right: auto;\"/>\n",
    "</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-instruct-ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
