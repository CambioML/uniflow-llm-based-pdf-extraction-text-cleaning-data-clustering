{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for GoogleMultiModalFlow \n",
    "\n",
    "In this example, we will show you how to use MultiModal as a classifier using Google's models via uniflow.\n",
    "\n",
    "### Before running the code\n",
    "\n",
    "You will need to `uniflow` conda environment to run this notebook. You can set up the environment following the instruction:\n",
    "```\n",
    "conda create -n uniflow python=3.10 -y\n",
    "conda activate uniflow  # some OS requires `source activate uniflow`\n",
    "```\n",
    "\n",
    "Next, you will need a valid [Google API key](https://ai.google.dev/tutorials/setup) to run the code. Once you have the key, set it as the environment variable `GOOGLE_API_KEY` within a `.env` file in the root directory of this repository. For more details, see this [instruction](https://github.com/CambioML/uniflow/tree/main#api-keys)\n",
    "\n",
    "### Update system path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL.Image\n",
    "import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display\n",
    "\n",
    "from uniflow import PromptTemplate\n",
    "from uniflow.flow.client import TransformClient\n",
    "from uniflow.flow.flow_factory import FlowFactory\n",
    "from uniflow.flow.config  import TransformConfig\n",
    "from uniflow.op.model.model_config  import GoogleMultiModalModelConfig\n",
    "from uniflow.viz import Viz\n",
    "from uniflow.op.prompt import Context\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the different flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extract': ['ExtractHTMLFlow',\n",
       "  'ExtractImageFlow',\n",
       "  'ExtractIpynbFlow',\n",
       "  'ExtractMarkdownFlow',\n",
       "  'ExtractPDFFlow',\n",
       "  'ExtractTxtFlow'],\n",
       " 'transform': ['TransformAzureOpenAIFlow',\n",
       "  'TransformCopyFlow',\n",
       "  'TransformGoogleFlow',\n",
       "  'TransformGoogleMultiModalModelFlow',\n",
       "  'TransformHuggingFaceFlow',\n",
       "  'TransformLMQGFlow',\n",
       "  'TransformOpenAIFlow'],\n",
       " 'rater': ['RaterFlow']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FlowFactory.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Prompts\n",
    "Here, we will load all images that needs to be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [\n",
    "    PIL.Image.open('data/dog.jpeg'),\n",
    "    PIL.Image.open('data/cat.jpeg'),\n",
    "    PIL.Image.open('data/monkey.jpeg'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for the given raw text strings `raw_context_input` above, we convert them to the `Context` class to be processed by `uniflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = [\n",
    "    Context(context=c)\n",
    "    for c in input\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LLM to generate data\n",
    "In this example, we use the base `Config` defaults with the GoogleModelConfig to generate questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TransformConfig(\n",
    "    flow_name=\"TransformGoogleMultiModalModelFlow\",\n",
    "    model_config=GoogleMultiModalModelConfig(),\n",
    "    prompt_template=PromptTemplate( # update with your prompt.\n",
    "        instruction=\"\"\"You are a multimodal AI model designed to classify images based on their content.\n",
    "        Your specific task is to determine whether the provided image is dog or cat.\n",
    "        Answer dog if dog is in image, cat if cat is in image, and neither if neither dog or cat is in image.\n",
    "        Explain your answer step by step, then output your result.\n",
    "        Your output should be in format. Explain: ... Answer: dog, cat, neither.\"\"\",\n",
    "    ),\n",
    ")\n",
    "client = TransformClient(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call the `run` method on the `client` object to execute the question-answer generation operation on the data shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:12<00:00,  4.20s/it]\n"
     ]
    }
   ],
   "source": [
    "output = client.run(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the output\n",
    "\n",
    "Let's take a look of the generated output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'output': [{'error': 'No errors.',\n",
      "              'response': [' **Explain:** The image shows a golden retriever '\n",
      "                           'puppy sitting on green grass. The puppy is looking '\n",
      "                           'up at something off camera. There are yellow '\n",
      "                           'flowers scattered on the ground around the puppy.\\n'\n",
      "                           '\\n'\n",
      "                           '**Answer:** dog']}],\n",
      "  'root': <uniflow.node.Node object at 0x106bbc0a0>},\n",
      " {'output': [{'error': 'No errors.',\n",
      "              'response': [' Explain: The image shows a gray cat with stripes '\n",
      "                           'lying on a white surface. The cat is looking at '\n",
      "                           'the camera.\\n'\n",
      "                           'Answer: cat']}],\n",
      "  'root': <uniflow.node.Node object at 0x1061b36a0>},\n",
      " {'output': [{'error': 'No errors.',\n",
      "              'response': [' There is a monkey in the image.\\n'\n",
      "                           'Explain: The image shows a monkey sitting on a '\n",
      "                           'tree branch. The monkey is looking at the camera. '\n",
      "                           'It has brown fur and a long tail.\\n'\n",
      "                           'Answer: neither']}],\n",
      "  'root': <uniflow.node.Node object at 0x1168a33a0>}]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
