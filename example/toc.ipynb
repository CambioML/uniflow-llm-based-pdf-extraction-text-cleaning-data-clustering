{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use LLM to Write a Table of Content (TOC) of All Example Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries\n",
    "\n",
    "Install the packages for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q pandas tabulate uniflow==0.0.26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goldpiggy/anaconda3/envs/0227/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# Adjusting display settings to avoid truncation\n",
    "pd.set_option('display.max_rows', None)  # Adjust to display all rows\n",
    "pd.set_option('display.max_columns', None)  # Adjust to display all columns\n",
    "pd.set_option('display.width', 20)  # Adjust to ensure each row uses optimal width\n",
    "# pd.set_option('display.max_colwidth', None)  # Adjust to display full content of each cell\n",
    "\n",
    "from uniflow.flow.client import TransformClient\n",
    "from uniflow.flow.flow_factory import FlowFactory\n",
    "from uniflow.flow.config import TransformConfig\n",
    "from uniflow.op.model.model_config import OpenAIModelConfig\n",
    "from uniflow.viz import Viz\n",
    "from uniflow.op.prompt import PromptTemplate, Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all the notebooks (which will be in the TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_ipynb_files(directory):\n",
    "    ipynb_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.ipynb'):\n",
    "                ipynb_files.append(os.path.join(root, file))\n",
    "    return ipynb_files\n",
    "\n",
    "# Replace with the actual path to the cloned 'example' directory\n",
    "all_ipynb = list_ipynb_files('./')\n",
    "len(all_ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./toc.ipynb',\n",
       " './rater/openai_evaluate_answer_completeness_accuracy_for_given_questions.ipynb',\n",
       " './rater/openai_compare_generated_answers_to_grounding_answer.ipynb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ipynb[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link the github url for each jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/toc.ipynb',\n",
       " 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_evaluate_answer_completeness_accuracy_for_given_questions.ipynb',\n",
       " 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_compare_generated_answers_to_grounding_answer.ipynb']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_url = \"https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example\"\n",
    "all_ipynb_urls = [home_url+ipynb[1:] for ipynb in all_ipynb]\n",
    "all_ipynb_urls[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Uniflow `TransformClient` to generate the summary for each notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "Assume you are an experienced ML technical writer known well about uniflow (https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering). Here is a list of jupyter notebooks using uniflow. For each notebook, do following tasks only once:\n",
    "1. retrieve the exactly title of each notebook, i.e. the notebook header. Only one title per each notebook. \n",
    "2. provide a 3-sentence, concise, unique and informative summary of each notebook. \n",
    "3. identify the input data type each notebook is using (including PDF, HTML, TXT, Jupyter Notebook, etc). \n",
    "4. identify the uniflow model type each notebook is using (such as 'TransformAzureOpenAIFlow', 'TransformGoogleFlow', 'TransformGoogleMultiModalModelFlow','TransformHuggingFaceFlow', 'TransformLMQGFlow', 'TransformOpenAIFlow', etc.)\n",
    "\n",
    "For each notebook, return a dictionary of keys of title, summary, input_data_type, uniflow_type and url.\n",
    "\"\"\"\n",
    "\n",
    "transform_config = TransformConfig(\n",
    "    flow_name=\"TransformOpenAIFlow\",\n",
    "    model_config=OpenAIModelConfig(\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0),\n",
    "    prompt_template=PromptTemplate(\n",
    "            instruction=instruction,\n",
    "            few_shot_prompt=[\n",
    "                Context(\n",
    "                    context=\"\"\"...\"\"\",\n",
    "                    title=\"\"\"...\"\"\",\n",
    "                    summary=\"\"\"...\"\"\",\n",
    "                    input_data_type=\"\"\"...\"\"\",\n",
    "                    uniflow_type=\"\"\"...\"\"\",\n",
    "                    url=\"\"\"...\"\"\",\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data to Uniflow input format (for better data output stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ipynb_urls_context = [Context(context={\"filename\": c}) for c in all_ipynb_urls]\n",
    "\n",
    "data = all_ipynb_urls_context[1:] ## ignore the first jupyter, which is this file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the `TransformClient` (may take a few minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:02<00:00,  2.60s/it]\n"
     ]
    }
   ],
   "source": [
    "client = TransformClient(transform_config)\n",
    "client_output = client.run(data) \n",
    "# client_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning',\n",
       "        'summary': 'This notebook demonstrates the process of extracting text from PDF documents and cleaning the text data for further analysis. It includes techniques for handling noisy and unstructured text data.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformLMQGFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pdf_extraction_text_cleaning.ipynb'},\n",
       "       {'title': 'Data Clustering with Uniflow',\n",
       "        'summary': 'This notebook showcases the application of Uniflow for data clustering, using advanced language models to group similar data points together. It provides insights into the clustering process and its potential applications.',\n",
       "        'input_data_type': 'Jupyter Notebook',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/data_clustering_with_uniflow.ipynb'},\n",
       "       {'title': 'Text Summarization using Uniflow',\n",
       "        'summary': 'This notebook explores the use of Uniflow for text summarization, condensing large volumes of text into concise summaries. It covers various techniques and models for effective summarization.',\n",
       "        'input_data_type': 'TXT',\n",
       "        'uniflow_type': 'TransformGoogleMultiModalModelFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/text_summarization_with_uniflow.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x1213824d0>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning',\n",
       "        'summary': 'This notebook demonstrates the process of extracting text from PDF documents and cleaning the text data for further analysis. It includes techniques for handling noisy and unstructured text data.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformLMQGFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pdf_extraction_text_cleaning.ipynb'},\n",
       "       {'title': 'Data Clustering with Uniflow',\n",
       "        'summary': 'This notebook showcases the application of Uniflow for data clustering, using advanced machine learning models to group similar data points together. It provides insights into the clustering process and model performance.',\n",
       "        'input_data_type': 'Jupyter Notebook',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/data_clustering_with_uniflow.ipynb'},\n",
       "       {'title': 'Comparing Generated Answers to Ground Truth',\n",
       "        'summary': 'This notebook compares the answers generated by Uniflow models with the ground truth answers, providing an evaluation of model performance and accuracy. It offers a comprehensive analysis of the generated answers.',\n",
       "        'input_data_type': 'Jupyter Notebook',\n",
       "        'uniflow_type': 'TransformOpenAIFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_compare_generated_answers_to_grounding_answer.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x121380310>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'Bedrock Evaluate Answer Completeness Accuracy for Given Questions',\n",
       "        'summary': 'This notebook uses uniflow to evaluate the completeness and accuracy of answers for given questions using the Bedrock model. It provides insights into the quality of the answers and helps in identifying any missing or inaccurate information.',\n",
       "        'input_data_type': 'Jupyter Notebook',\n",
       "        'uniflow_type': 'BedrockFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/bedrock_evaluate_answer_completeness_accuracy_for_given_questions.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d1a260>},\n",
       " {'output': [{'response': [{'title': 'Huggingface Evaluate Answer Completeness Accuracy for Given Questions',\n",
       "      'summary': 'This notebook demonstrates how to use uniflow with Huggingface model to evaluate the completeness and accuracy of answers for given questions. It provides a concise evaluation of the performance of the Huggingface model in answering specific questions.',\n",
       "      'input_data_type': 'Jupyter Notebook',\n",
       "      'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "      'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/huggingface_evaluate_answer_completeness_accuracy_for_given_questions.ipynb.ipynb'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d1af80>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning',\n",
       "        'summary': 'This notebook demonstrates the process of extracting text from PDF documents and cleaning the text data for further analysis. It includes steps for preprocessing and transforming the text data using uniflow.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_s3_txt.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d1b820>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the extracted text for further processing. It includes steps for preprocessing and transforming the extracted text data.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_pdf_extract_transform.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d1aa10>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'Pipeline Web Summary',\n",
       "        'summary': 'This notebook demonstrates the use of uniflow for extracting text from web pages, cleaning the text data, and clustering the data for summarization. It provides a pipeline for web data summarization using uniflow.',\n",
       "        'input_data_type': 'Web pages (HTML)',\n",
       "        'uniflow_type': 'LLM-based PDF extraction, text cleaning, data clustering',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_web_summary.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d19c30>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning',\n",
       "        'summary': 'This notebook demonstrates the use of uniflow for extracting text from PDF documents and cleaning the text data for further processing. It includes steps for preprocessing and preparing the text data for clustering or other NLP tasks.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_pdf.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d1b850>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the text data for further processing. It includes steps for preprocessing the extracted text and preparing it for data clustering.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/vector_database/pdf_extraction_text_cleaning.ipynb'},\n",
       "       {'title': 'Data Clustering with Uniflow',\n",
       "        'summary': 'This notebook showcases the use of uniflow for clustering text data using advanced language models. It covers the process of data preprocessing, model training, and evaluating the clustering results.',\n",
       "        'input_data_type': 'TXT',\n",
       "        'uniflow_type': 'TransformLMQGFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/vector_database/data_clustering_uniflow.ipynb'},\n",
       "       {'title': 'HTML Data Processing using Uniflow',\n",
       "        'summary': 'In this notebook, uniflow is utilized to process and analyze HTML data for various NLP tasks. It demonstrates the workflow for ingesting HTML data, applying language models, and extracting valuable insights.',\n",
       "        'input_data_type': 'HTML',\n",
       "        'uniflow_type': 'TransformGoogleMultiModalModelFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/vector_database/html_data_processing_uniflow.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d1b1f0>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the text data for further processing. It includes steps for preprocessing the extracted text and preparing it for data clustering.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/vector_database/PDF_extraction_and_text_cleaning.ipynb'},\n",
       "       {'title': 'Data Clustering with Uniflow',\n",
       "        'summary': 'This notebook showcases the application of uniflow for clustering text data using the extracted features. It covers the process of using uniflow models for data clustering and visualizing the clustered results.',\n",
       "        'input_data_type': 'Text',\n",
       "        'uniflow_type': 'TransformGoogleMultiModalModelFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/vector_database/data_clustering_with_uniflow.ipynb'},\n",
       "       {'title': 'Named Entity Recognition from PDF',\n",
       "        'summary': 'In this notebook, uniflow is utilized for extracting named entities from PDF documents. It demonstrates the process of leveraging uniflow models for identifying and extracting named entities from PDF text data.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformOpenAIFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/vector_database/named_entity_recognition_from_PDF.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d1b910>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'Extract PDF with Recursive Splitter',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow to extract text from PDF files using a recursive splitter method, which is useful for handling complex PDF structures. It also includes text cleaning and data clustering techniques for further analysis.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'LLM-based PDF Extraction Text Cleaning Data Clustering',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_pdf_with_recursive_splitter.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d1bd60>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the extracted text for further processing. It includes preprocessing steps such as text cleaning and normalization.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_pdf.ipynb'},\n",
       "       {'title': 'HTML Extraction',\n",
       "        'summary': 'This notebook showcases the process of extracting text from HTML documents using uniflow. It covers the extraction of structured data from HTML and conversion into a usable format for analysis.',\n",
       "        'input_data_type': 'HTML',\n",
       "        'uniflow_type': 'TransformGoogleFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_html.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x12155e6b0>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'Extracting text from Markdown files',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow to extract text from Markdown files and clean the extracted text for further processing. It also showcases data clustering using the extracted text.',\n",
       "        'input_data_type': 'Markdown files',\n",
       "        'uniflow_type': 'LLM-based PDF extraction, text cleaning, data clustering',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_md.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d5c280>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'Extract PDF Nougat QA',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow for extracting text from PDF documents and performing text cleaning and data clustering. It includes a question-answering system for Nougat dataset.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'LLM-based PDF Extraction Text Cleaning Data Clustering',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_pdf_nougat_qa.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d5e770>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'Extract Text from PDF',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow to extract text from PDF documents and clean the extracted text data for further processing. It also showcases data clustering techniques for organizing the extracted text.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'LLM-based PDF Extraction Text Cleaning Data Clustering',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_txt.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124cf7970>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'Extract Text from PDF using Uniflow',\n",
       "        'summary': 'This notebook demonstrates how to use Uniflow to extract text from PDF documents and clean the extracted text for further analysis. It also showcases data clustering techniques using the extracted text.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'LLM-based PDF Extraction Text Cleaning Data Clustering',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_text_from_pdf.ipynb'},\n",
       "       {'title': 'Extract Text from HTML using Uniflow',\n",
       "        'summary': 'This notebook provides a guide on using Uniflow to extract text from HTML files and preprocess the extracted text for downstream tasks. It also includes examples of using different data clustering algorithms on the extracted text data.',\n",
       "        'input_data_type': 'HTML',\n",
       "        'uniflow_type': 'LLM-based PDF Extraction Text Cleaning Data Clustering',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_text_from_html.ipynb'},\n",
       "       {'title': 'Clean and Preprocess Text Data using Uniflow',\n",
       "        'summary': 'This notebook demonstrates the process of cleaning and preprocessing text data using Uniflow, including techniques for handling noisy and unstructured text data. It also showcases the use of Uniflow for data clustering and analysis.',\n",
       "        'input_data_type': 'TXT',\n",
       "        'uniflow_type': 'LLM-based PDF Extraction Text Cleaning Data Clustering',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/preprocess/clean_preprocess_text_data.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d574f0>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the text data for further processing. It includes preprocessing steps such as text extraction, cleaning, and normalization.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformOpenAIFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/pdf_extraction_text_cleaning.ipynb'},\n",
       "       {'title': 'HTML Question Answering',\n",
       "        'summary': 'This notebook showcases the application of uniflow for performing question answering on HTML documents. It utilizes the OpenAI model for processing HTML content and generating relevant answers to user queries.',\n",
       "        'input_data_type': 'HTML',\n",
       "        'uniflow_type': 'TransformOpenAIFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_html_QA.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d56bc0>},\n",
       " {'output': [{'response': [{'title': 'OpenAI PDF Source 10k Summary',\n",
       "      'summary': 'This notebook demonstrates the use of uniflow for extracting text from PDF documents, cleaning the text data, and clustering the data to generate a summary of 10k reports. It showcases the capabilities of uniflow in processing large volumes of PDF data efficiently.',\n",
       "      'input_data_type': 'PDF',\n",
       "      'uniflow_type': 'TransformOpenAIFlow',\n",
       "      'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_pdf_source_10k_summary.ipynb'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d57160>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning using Uniflow',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the text data for further processing. It includes preprocessing steps such as text extraction, cleaning, and normalization.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformGoogleFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/google_model.ipynb'},\n",
       "       {'title': 'Data Clustering with Uniflow',\n",
       "        'summary': \"This notebook showcases the use of uniflow for clustering text data using advanced language models. It covers the process of data preprocessing, feature extraction, and clustering using uniflow's model.\",\n",
       "        'input_data_type': 'TXT',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/huggingface_model.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d57e80>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'OpenAI Jupyter Notebook QA',\n",
       "        'summary': \"This notebook demonstrates how to use uniflow for question answering on Jupyter notebooks using OpenAI's GPT-3 model. It provides a step-by-step guide on how to set up the environment, input the Jupyter notebook, and generate answers to user queries.\",\n",
       "        'input_data_type': 'Jupyter Notebook',\n",
       "        'uniflow_type': 'TransformOpenAIFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_jupyter_notebook_QA.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d57790>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning with Uniflow',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the text data for further processing. It includes examples of preprocessing steps and data clustering using uniflow.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/pdf_extraction_text_cleaning.ipynb'},\n",
       "       {'title': 'Data Clustering with Uniflow',\n",
       "        'summary': 'This notebook focuses on using uniflow for clustering text data. It provides examples of how to prepare the data, apply clustering algorithms, and visualize the clustered results using uniflow.',\n",
       "        'input_data_type': 'TXT',\n",
       "        'uniflow_type': 'TransformLMQGFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/data_clustering.ipynb'},\n",
       "       {'title': 'Multi-Modal Data Processing with Uniflow',\n",
       "        'summary': 'This notebook showcases the capabilities of uniflow for processing multi-modal data, including text, images, and other types of data. It demonstrates how to use uniflow to handle diverse data types and perform data clustering.',\n",
       "        'input_data_type': 'Multi-Modal (e.g., Text, Images)',\n",
       "        'uniflow_type': 'TransformGoogleMultiModalModelFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/multi_modal_data_processing.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d25fc0>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'PDF Extraction and Text Cleaning',\n",
       "        'summary': 'This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the text data for further processing. It includes preprocessing steps such as text extraction, cleaning, and normalization.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformGoogleMultiModalModelFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/google_multimodal_model.ipynb'},\n",
       "       {'title': 'Data Clustering with Uniflow',\n",
       "        'summary': 'This notebook showcases the application of uniflow for data clustering using the provided input data. It covers the process of data preprocessing, feature extraction, and clustering using the uniflow model.',\n",
       "        'input_data_type': 'Jupyter Notebook',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/data_clustering.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d25180>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'OpenAI PDF Source 10k QA',\n",
       "        'summary': 'This notebook demonstrates the use of uniflow for extracting text from PDF documents, cleaning the text data, and clustering the data using OpenAI model. It includes a question-answering task on a dataset of 10k PDF documents.',\n",
       "        'input_data_type': 'PDF',\n",
       "        'uniflow_type': 'TransformOpenAIFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_pdf_source_10k_QA.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d26320>},\n",
       " {'output': [{'response': [{'notebooks': [{'title': 'HuggingFace Model Benchmark G5',\n",
       "        'summary': \"This notebook benchmarks the performance of the HuggingFace model G5 for text extraction and data clustering using uniflow. It compares the model's accuracy, speed, and resource consumption.\",\n",
       "        'input_data_type': 'Jupyter Notebook',\n",
       "        'uniflow_type': 'TransformHuggingFaceFlow',\n",
       "        'url': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/huggingface_model_benchmark_g5.ipynb'}]}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.Node at 0x124d241f0>}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_output[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the outputs\n",
    "\n",
    "Parsing the LLMs is quite tricky. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'notebooks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m notebook \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnotebooks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m      9\u001b[0m             row \u001b[38;5;241m=\u001b[39m {column: notebook[column] \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m df_columns}\n\u001b[1;32m     10\u001b[0m             rows\u001b[38;5;241m.\u001b[39mappend(row)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'notebooks'"
     ]
    }
   ],
   "source": [
    "# Parsing the JSON data into a DataFrame\n",
    "df_columns = ['title', 'summary', 'input_data_type', 'uniflow_type', 'url']\n",
    "rows = []\n",
    "\n",
    "for item in client_output:\n",
    "    for output in item['output']:\n",
    "        for response in output['response']:\n",
    "            for notebook in response['notebooks']:\n",
    "                row = {column: notebook[column] for column in df_columns}\n",
    "                rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=df_columns)\n",
    "df = df.set_index('title')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'notebooks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 8\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m notebook \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnotebooks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m      9\u001b[0m                 flattened_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     10\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: notebook[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     11\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m: notebook[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m: notebook[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m                 })\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'notebooks'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = []\n",
    "for item in client_output:\n",
    "    for output in item['output']:\n",
    "        for response in output['response']:\n",
    "            for notebook in response['notebooks']:\n",
    "                flattened_data.append({\n",
    "                    'title': notebook['title'],\n",
    "                    'summary': notebook['summary'],\n",
    "                    'input_data_type': notebook['input_data_type'],\n",
    "                    'uniflow_type': notebook['uniflow_type'],\n",
    "                    'url': notebook['url']\n",
    "                })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "df = df.set_index('title')\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output cleaning\n",
    "It seems that LLMs make up some data. let's remove those fake rows in the dataframe. Here are the criteria: if the url is not start with `home_url`, that means LLMs make up this row so we can remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the home_url\n",
    "home_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>input_data_type</th>\n",
       "      <th>uniflow_type</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OpenAI Evaluate Answer Completeness Accuracy for Given Questions</th>\n",
       "      <td>This notebook uses uniflow to evaluate the completeness and accuracy of answers for given questions using OpenAI model. It provides insights into the performance of the model in generating accurate and complete answers.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_evaluate_answer_completeness_accuracy_for_given_questions.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI Compare Generated Answers to Grounding Answer</th>\n",
       "      <td>This notebook compares the answers generated by OpenAI language model to a grounding answer for evaluation. It provides a method to assess the quality of the generated answers.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_compare_generated_answers_to_grounding_answer.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedrock Evaluate Answer Completeness Accuracy for Given Questions</th>\n",
       "      <td>This notebook uses uniflow to evaluate the completeness and accuracy of answers for given questions using the Bedrock model. It provides insights into the quality of answers and helps in identifying areas for improvement.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>BedrockFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/bedrock_evaluate_answer_completeness_accuracy_for_given_questions.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huggingface Evaluate Answer Completeness Accuracy for Given Questions</th>\n",
       "      <td>This notebook uses Huggingface model to evaluate the completeness and accuracy of answers for given questions. It provides a comprehensive analysis of the model's performance in understanding and answering questions.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformHuggingFaceFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/huggingface_evaluate_answer_completeness_accuracy_for_given_questions.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDF Extraction and Text Cleaning with Uniflow</th>\n",
       "      <td>This notebook demonstrates how to use uniflow for PDF extraction and text cleaning, including data clustering for further analysis. It provides a step-by-step guide for processing PDF data and preparing it for clustering.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_s3_txt.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDF Extraction and Text Cleaning with Data Clustering</th>\n",
       "      <td>This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis. It provides a comprehensive pipeline for preprocessing PDF data and preparing it for downstream tasks.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_pdf_extract_transform.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline Web Summary</th>\n",
       "      <td>This notebook demonstrates the use of uniflow for PDF extraction, text cleaning, and data clustering to generate a summary of web content. It showcases the end-to-end pipeline for web content analysis using uniflow.</td>\n",
       "      <td>PDF, HTML</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_web_summary.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDF Extraction and Text Cleaning with Data Clustering</th>\n",
       "      <td>This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_pdf.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLM Based PDF Extraction, Text Cleaning, Data Clustering</th>\n",
       "      <td>This notebook demonstrates the use of LLM for PDF extraction, text cleaning, and data clustering. It showcases the end-to-end workflow of processing PDF documents, cleaning the text data, and clustering similar documents based on their content.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLLMFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/vector_database/setup_resources.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extract PDF with Recursive Splitter</th>\n",
       "      <td>This notebook demonstrates how to use uniflow to extract text from PDF files using a recursive splitter, and then clean the extracted text data. It also showcases data clustering techniques to organize the extracted text data.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_pdf_with_recursive_splitter.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extract HTML</th>\n",
       "      <td>This notebook demonstrates how to use uniflow to extract text from HTML documents and clean the extracted text for data clustering. It also provides examples of using LLM-based PDF extraction for text cleaning.</td>\n",
       "      <td>HTML</td>\n",
       "      <td>TransformLLMFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_html.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extracting Text from PDF and Cleaning Data for Clustering</th>\n",
       "      <td>This notebook demonstrates how to use uniflow to extract text from PDF and clean the data for clustering. It includes preprocessing steps such as text extraction, data cleaning, and feature engineering.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_md.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extract PDF Nougat QA</th>\n",
       "      <td>This notebook demonstrates the process of extracting text from PDF documents using uniflow's LLM-based PDF extraction and performing data cleaning and clustering for QA purposes.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>LLM-based PDF Extraction</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_pdf_nougat_qa.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extract Text from PDF</th>\n",
       "      <td>This notebook demonstrates how to use uniflow to extract text from PDF documents, clean the extracted text, and perform data clustering for further analysis.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_txt.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extract Text from PDF and Clean</th>\n",
       "      <td>This notebook demonstrates how to extract text from PDF files and clean the extracted text for further processing. It includes techniques for handling special characters, removing noise, and normalizing the text data.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_txt_from_s3.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDF Extraction and Text Cleaning with Data Clustering</th>\n",
       "      <td>This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_html_QA.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Question Answering with OpenAI GPT-3 on HTML Data</th>\n",
       "      <td>Using OpenAI GPT-3 model, this notebook performs question answering on HTML data, demonstrating the capability of the model to understand and respond to questions based on the provided HTML content.</td>\n",
       "      <td>HTML</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_html_QA.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI PDF Source 10k Summary</th>\n",
       "      <td>This notebook demonstrates the use of uniflow for extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data. It provides a summary of 10k PDF documents using OpenAI model.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_pdf_source_10k_summary.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI Jupyter Notebook QA</th>\n",
       "      <td>This notebook demonstrates how to use uniflow to perform question answering on Jupyter notebooks using OpenAI's language model. It includes examples of extracting text from Jupyter notebooks, cleaning the text, and performing data clustering.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_jupyter_notebook_QA.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huggingface Model Benchmark Neuron</th>\n",
       "      <td>This notebook benchmarks the performance of a Huggingface model for text extraction and data clustering using uniflow. It compares the model's speed and accuracy with different input data.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformHuggingFaceFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/huggingface_model_benchmark_neuron.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDF Extraction and Text Cleaning with Uniflow</th>\n",
       "      <td>This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the text data for further analysis. It includes preprocessing steps such as text extraction, text cleaning, and data clustering.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformGoogleMultiModalModelFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/google_multimodal_model.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI PDF Source 10k QA</th>\n",
       "      <td>This notebook demonstrates the use of uniflow for extracting text from PDF documents, cleaning the text data, and clustering the data using OpenAI's language model. It also includes a question-answering task on the extracted text data.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_pdf_source_10k_QA.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huggingface Model Benchmark G5</th>\n",
       "      <td>This notebook benchmarks the performance of a Huggingface model G5 for text extraction and data clustering using uniflow. It compares the model's accuracy and efficiency in processing large datasets.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformHuggingFaceFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/huggingface_model_benchmark_g5.ipynb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                       summary  \\\n",
       "title                                                                                                                                                                                                                                                                                                                                            \n",
       "OpenAI Evaluate Answer Completeness Accuracy for Given Questions                                                   This notebook uses uniflow to evaluate the completeness and accuracy of answers for given questions using OpenAI model. It provides insights into the performance of the model in generating accurate and complete answers.   \n",
       "OpenAI Compare Generated Answers to Grounding Answer                                                                                                          This notebook compares the answers generated by OpenAI language model to a grounding answer for evaluation. It provides a method to assess the quality of the generated answers.   \n",
       "Bedrock Evaluate Answer Completeness Accuracy for Given Questions                                                This notebook uses uniflow to evaluate the completeness and accuracy of answers for given questions using the Bedrock model. It provides insights into the quality of answers and helps in identifying areas for improvement.   \n",
       "Huggingface Evaluate Answer Completeness Accuracy for Given Questions                                                 This notebook uses Huggingface model to evaluate the completeness and accuracy of answers for given questions. It provides a comprehensive analysis of the model's performance in understanding and answering questions.   \n",
       "PDF Extraction and Text Cleaning with Uniflow                                                                    This notebook demonstrates how to use uniflow for PDF extraction and text cleaning, including data clustering for further analysis. It provides a step-by-step guide for processing PDF data and preparing it for clustering.   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                  This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis. It provides a comprehensive pipeline for preprocessing PDF data and preparing it for downstream tasks.   \n",
       "Pipeline Web Summary                                                                                                   This notebook demonstrates the use of uniflow for PDF extraction, text cleaning, and data clustering to generate a summary of web content. It showcases the end-to-end pipeline for web content analysis using uniflow.   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                                                                                                         This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis.   \n",
       "LLM Based PDF Extraction, Text Cleaning, Data Clustering                                  This notebook demonstrates the use of LLM for PDF extraction, text cleaning, and data clustering. It showcases the end-to-end workflow of processing PDF documents, cleaning the text data, and clustering similar documents based on their content.   \n",
       "Extract PDF with Recursive Splitter                                                                         This notebook demonstrates how to use uniflow to extract text from PDF files using a recursive splitter, and then clean the extracted text data. It also showcases data clustering techniques to organize the extracted text data.   \n",
       "Extract HTML                                                                                                                This notebook demonstrates how to use uniflow to extract text from HTML documents and clean the extracted text for data clustering. It also provides examples of using LLM-based PDF extraction for text cleaning.   \n",
       "Extracting Text from PDF and Cleaning Data for Clustering                                                                           This notebook demonstrates how to use uniflow to extract text from PDF and clean the data for clustering. It includes preprocessing steps such as text extraction, data cleaning, and feature engineering.   \n",
       "Extract PDF Nougat QA                                                                                                                                       This notebook demonstrates the process of extracting text from PDF documents using uniflow's LLM-based PDF extraction and performing data cleaning and clustering for QA purposes.   \n",
       "Extract Text from PDF                                                                                                                                                            This notebook demonstrates how to use uniflow to extract text from PDF documents, clean the extracted text, and perform data clustering for further analysis.   \n",
       "Extract Text from PDF and Clean                                                                                      This notebook demonstrates how to extract text from PDF files and clean the extracted text for further processing. It includes techniques for handling special characters, removing noise, and normalizing the text data.   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                                                                                                         This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis.   \n",
       "Question Answering with OpenAI GPT-3 on HTML Data                                                                                       Using OpenAI GPT-3 model, this notebook performs question answering on HTML data, demonstrating the capability of the model to understand and respond to questions based on the provided HTML content.   \n",
       "OpenAI PDF Source 10k Summary                                                                                               This notebook demonstrates the use of uniflow for extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data. It provides a summary of 10k PDF documents using OpenAI model.   \n",
       "OpenAI Jupyter Notebook QA                                                                  This notebook demonstrates how to use uniflow to perform question answering on Jupyter notebooks using OpenAI's language model. It includes examples of extracting text from Jupyter notebooks, cleaning the text, and performing data clustering.   \n",
       "Huggingface Model Benchmark Neuron                                                                                                                This notebook benchmarks the performance of a Huggingface model for text extraction and data clustering using uniflow. It compares the model's speed and accuracy with different input data.   \n",
       "PDF Extraction and Text Cleaning with Uniflow                                                               This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the text data for further analysis. It includes preprocessing steps such as text extraction, text cleaning, and data clustering.   \n",
       "OpenAI PDF Source 10k QA                                                                           This notebook demonstrates the use of uniflow for extracting text from PDF documents, cleaning the text data, and clustering the data using OpenAI's language model. It also includes a question-answering task on the extracted text data.   \n",
       "Huggingface Model Benchmark G5                                                                                                         This notebook benchmarks the performance of a Huggingface model G5 for text extraction and data clustering using uniflow. It compares the model's accuracy and efficiency in processing large datasets.   \n",
       "\n",
       "                                                                        input_data_type  \\\n",
       "title                                                                                     \n",
       "OpenAI Evaluate Answer Completeness Accuracy for Given Questions       Jupyter Notebook   \n",
       "OpenAI Compare Generated Answers to Grounding Answer                   Jupyter Notebook   \n",
       "Bedrock Evaluate Answer Completeness Accuracy for Given Questions      Jupyter Notebook   \n",
       "Huggingface Evaluate Answer Completeness Accuracy for Given Questions  Jupyter Notebook   \n",
       "PDF Extraction and Text Cleaning with Uniflow                                       PDF   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                               PDF   \n",
       "Pipeline Web Summary                                                          PDF, HTML   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                               PDF   \n",
       "LLM Based PDF Extraction, Text Cleaning, Data Clustering                            PDF   \n",
       "Extract PDF with Recursive Splitter                                                 PDF   \n",
       "Extract HTML                                                                       HTML   \n",
       "Extracting Text from PDF and Cleaning Data for Clustering                           PDF   \n",
       "Extract PDF Nougat QA                                                               PDF   \n",
       "Extract Text from PDF                                                               PDF   \n",
       "Extract Text from PDF and Clean                                                     PDF   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                               PDF   \n",
       "Question Answering with OpenAI GPT-3 on HTML Data                                  HTML   \n",
       "OpenAI PDF Source 10k Summary                                                       PDF   \n",
       "OpenAI Jupyter Notebook QA                                             Jupyter Notebook   \n",
       "Huggingface Model Benchmark Neuron                                     Jupyter Notebook   \n",
       "PDF Extraction and Text Cleaning with Uniflow                                       PDF   \n",
       "OpenAI PDF Source 10k QA                                                            PDF   \n",
       "Huggingface Model Benchmark G5                                         Jupyter Notebook   \n",
       "\n",
       "                                                                                             uniflow_type  \\\n",
       "title                                                                                                       \n",
       "OpenAI Evaluate Answer Completeness Accuracy for Given Questions                      TransformOpenAIFlow   \n",
       "OpenAI Compare Generated Answers to Grounding Answer                                  TransformOpenAIFlow   \n",
       "Bedrock Evaluate Answer Completeness Accuracy for Given Questions                             BedrockFlow   \n",
       "Huggingface Evaluate Answer Completeness Accuracy for Given Questions            TransformHuggingFaceFlow   \n",
       "PDF Extraction and Text Cleaning with Uniflow                                           TransformLMQGFlow   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                   TransformLMQGFlow   \n",
       "Pipeline Web Summary                                                                    TransformLMQGFlow   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                   TransformLMQGFlow   \n",
       "LLM Based PDF Extraction, Text Cleaning, Data Clustering                                 TransformLLMFlow   \n",
       "Extract PDF with Recursive Splitter                                                     TransformLMQGFlow   \n",
       "Extract HTML                                                                             TransformLLMFlow   \n",
       "Extracting Text from PDF and Cleaning Data for Clustering                               TransformLMQGFlow   \n",
       "Extract PDF Nougat QA                                                            LLM-based PDF Extraction   \n",
       "Extract Text from PDF                                                                   TransformLMQGFlow   \n",
       "Extract Text from PDF and Clean                                                         TransformLMQGFlow   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                   TransformLMQGFlow   \n",
       "Question Answering with OpenAI GPT-3 on HTML Data                                     TransformOpenAIFlow   \n",
       "OpenAI PDF Source 10k Summary                                                         TransformOpenAIFlow   \n",
       "OpenAI Jupyter Notebook QA                                                            TransformOpenAIFlow   \n",
       "Huggingface Model Benchmark Neuron                                               TransformHuggingFaceFlow   \n",
       "PDF Extraction and Text Cleaning with Uniflow                          TransformGoogleMultiModalModelFlow   \n",
       "OpenAI PDF Source 10k QA                                                              TransformOpenAIFlow   \n",
       "Huggingface Model Benchmark G5                                                   TransformHuggingFaceFlow   \n",
       "\n",
       "                                                                                                                                                                                                                                                                  url  \n",
       "title                                                                                                                                                                                                                                                                  \n",
       "OpenAI Evaluate Answer Completeness Accuracy for Given Questions            https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_evaluate_answer_completeness_accuracy_for_given_questions.ipynb  \n",
       "OpenAI Compare Generated Answers to Grounding Answer                                    https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_compare_generated_answers_to_grounding_answer.ipynb  \n",
       "Bedrock Evaluate Answer Completeness Accuracy for Given Questions          https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/bedrock_evaluate_answer_completeness_accuracy_for_given_questions.ipynb  \n",
       "Huggingface Evaluate Answer Completeness Accuracy for Given Questions  https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/huggingface_evaluate_answer_completeness_accuracy_for_given_questions.ipynb  \n",
       "PDF Extraction and Text Cleaning with Uniflow                                                                             https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_s3_txt.ipynb  \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                                      https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_pdf_extract_transform.ipynb  \n",
       "Pipeline Web Summary                                                                                                 https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_web_summary.ipynb  \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                                                        https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_pdf.ipynb  \n",
       "LLM Based PDF Extraction, Text Cleaning, Data Clustering                                                           https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/vector_database/setup_resources.ipynb  \n",
       "Extract PDF with Recursive Splitter                                                                    https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_pdf_with_recursive_splitter.ipynb  \n",
       "Extract HTML                                                                                                                  https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_html.ipynb  \n",
       "Extracting Text from PDF and Cleaning Data for Clustering                                                                       https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_md.ipynb  \n",
       "Extract PDF Nougat QA                                                                                                https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_pdf_nougat_qa.ipynb  \n",
       "Extract Text from PDF                                                                                                          https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_txt.ipynb  \n",
       "Extract Text from PDF and Clean                                                                                        https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_txt_from_s3.ipynb  \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                                                     https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_html_QA.ipynb  \n",
       "Question Answering with OpenAI GPT-3 on HTML Data                                                                         https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_html_QA.ipynb  \n",
       "OpenAI PDF Source 10k Summary                                                                              https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_pdf_source_10k_summary.ipynb  \n",
       "OpenAI Jupyter Notebook QA                                                                                    https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_jupyter_notebook_QA.ipynb  \n",
       "Huggingface Model Benchmark Neuron                                                                    https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/huggingface_model_benchmark_neuron.ipynb  \n",
       "PDF Extraction and Text Cleaning with Uniflow                                                                    https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/google_multimodal_model.ipynb  \n",
       "OpenAI PDF Source 10k QA                                                                                        https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_pdf_source_10k_QA.ipynb  \n",
       "Huggingface Model Benchmark G5                                                                            https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/huggingface_model_benchmark_g5.ipynb  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where the 'url' column does not start with the specified prefix\n",
    "df_filtered = df[df['url'].str.startswith(home_url)]\n",
    "print(df_filtered.shape)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to markdown\n",
    "\n",
    "Now we can save the dataframe to a markdown file and use it in the README file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the markdown text to a .md file\n",
    "df_markdown = df_filtered.to_markdown(index=True)\n",
    "file_path = 'toc_examples.md'\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(df_markdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the notebook\n",
    "\n",
    "Check more Uniflow use cases in the [example folder](https://github.com/CambioML/uniflow/tree/main/example/model#examples)!\n",
    "\n",
    "<a href=\"https://www.cambioml.com/\" title=\"Title\">\n",
    "    <img src=\"./image/cambioml_logo_large.png\" style=\"height: 100px; display: block; margin-left: auto; margin-right: auto;\"/>\n",
    "</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
