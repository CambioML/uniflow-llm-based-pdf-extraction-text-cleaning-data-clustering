{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use LLM to Write a Table of Content (TOC) of All Example Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q pandas tabulate uniflow==0.0.29\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# Adjusting display settings to avoid truncation\n",
    "pd.set_option('display.max_rows', None)  # Adjust to display all rows\n",
    "pd.set_option('display.max_columns', None)  # Adjust to display all columns\n",
    "pd.set_option('display.width', 20)  # Adjust to ensure each row uses optimal width\n",
    "# pd.set_option('display.max_colwidth', None)  # Adjust to display full content of each cell\n",
    "\n",
    "from uniflow.flow.client import TransformClient\n",
    "from uniflow.flow.flow_factory import FlowFactory\n",
    "from uniflow.flow.config import TransformConfig\n",
    "from uniflow.op.model.model_config import OpenAIModelConfig\n",
    "from uniflow.viz import Viz\n",
    "from uniflow.op.prompt import PromptTemplate, Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_ipynb_files(directory):\n",
    "    ipynb_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.ipynb'):\n",
    "                ipynb_files.append(os.path.join(root, file))\n",
    "    return ipynb_files\n",
    "\n",
    "# Replace with the actual path to the cloned 'example' directory\n",
    "all_ipynb = list_ipynb_files('./')\n",
    "len(all_ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./toc.ipynb',\n",
       " './rater/openai_evaluate_answer_completeness_accuracy_for_given_questions.ipynb',\n",
       " './rater/openai_compare_generated_answers_to_grounding_answer.ipynb']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ipynb[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_url = \"https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/toc.ipynb',\n",
       " 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_evaluate_answer_completeness_accuracy_for_given_questions.ipynb',\n",
       " 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_compare_generated_answers_to_grounding_answer.ipynb']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## define the github url for each jupyter notebook\n",
    "all_ipynb_urls = [home_url+ipynb[1:] for ipynb in all_ipynb]\n",
    "all_ipynb_urls[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(context={'filename': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/toc.ipynb'}),\n",
       " Context(context={'filename': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_evaluate_answer_completeness_accuracy_for_given_questions.ipynb'}),\n",
       " Context(context={'filename': 'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_compare_generated_answers_to_grounding_answer.ipynb'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ipynb_urls_context = [Context(context={\"filename\": c}) for c in all_ipynb_urls]\n",
    "all_ipynb_urls_context[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "Assume you are an experienced ML technical writer known well about uniflow (https://www.cambioml.com/docs/uniflow/uniflow.flow.html#module-uniflow.flow.client). Here is a list of jupyter notebooks using uniflow. For each notebook, do following tasks only once:\n",
    "1. retrieve the exactly title of each notebook, i.e. the notebook header. Only one title per each notebook. \n",
    "2. provide a 3-sentence, concise, unique and informative summary of each notebook. \n",
    "3. identify the input data type each notebook is using (including PDF, HTML, TXT, Jupyter Notebook, etc). \n",
    "4. identify the uniflow model type each notebook is using (such as 'TransformAzureOpenAIFlow', 'TransformGoogleFlow', 'TransformGoogleMultiModalModelFlow','TransformHuggingFaceFlow', 'TransformLMQGFlow', 'TransformOpenAIFlow', etc.)\n",
    "Follow the format of the examples below to include each notebook's title, summary, input_data_type, uniflow_type and url in response. \n",
    "\"\"\"\n",
    "\n",
    "transform_config = TransformConfig(\n",
    "    flow_name=\"TransformOpenAIFlow\",\n",
    "    model_config=OpenAIModelConfig(\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0),\n",
    "    prompt_template=PromptTemplate(\n",
    "            instruction=instruction,\n",
    "            few_shot_prompt=[\n",
    "                Context(\n",
    "                    context=\"\"\"...\"\"\",\n",
    "                    title=\"\"\"...\"\"\",\n",
    "                    summary=\"\"\"...\"\"\",\n",
    "                    input_data_type=\"\"\"...\"\"\",\n",
    "                    uniflow_type=\"\"\"...\"\"\",\n",
    "                    url=\"\"\"...\"\"\",\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_ipynb_urls_context[1:] ## ignore the first jupyter, which is this file\n",
    "\n",
    "client = TransformClient(transform_config)\n",
    "client_output = client.run(data) \n",
    "# client_output ## uncomment it out if you want to print the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = []\n",
    "for item in client_output:\n",
    "    for output in item['output']:\n",
    "        for response in output['response']:\n",
    "            for notebook in response['notebooks']:\n",
    "                flattened_data.append({\n",
    "                    'title': notebook['title'],\n",
    "                    'summary': notebook['summary'],\n",
    "                    'input_data_type': notebook['input_data_type'],\n",
    "                    'uniflow_type': notebook['uniflow_type'],\n",
    "                    'url': notebook['url']\n",
    "                })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "df = df.set_index('title')\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output cleaning\n",
    "It seems that LLMs make up some data. let's remove those fake rows in the dataframe. Here are the criteria: if the url is not start with `home_url`, that means LLMs make up this row so we can remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the home_url\n",
    "home_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>input_data_type</th>\n",
       "      <th>uniflow_type</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OpenAI Evaluate Answer Completeness Accuracy for Given Questions</th>\n",
       "      <td>This notebook uses uniflow to evaluate the completeness and accuracy of answers for given questions using OpenAI model. It provides insights into the performance of the model in generating accurate and complete answers.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_evaluate_answer_completeness_accuracy_for_given_questions.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI Compare Generated Answers to Grounding Answer</th>\n",
       "      <td>This notebook compares the answers generated by OpenAI language model to a grounding answer for evaluation. It provides a method to assess the quality of the generated answers.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_compare_generated_answers_to_grounding_answer.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedrock Evaluate Answer Completeness Accuracy for Given Questions</th>\n",
       "      <td>This notebook uses uniflow to evaluate the completeness and accuracy of answers for given questions using the Bedrock model. It provides insights into the quality of answers and helps in identifying areas for improvement.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>BedrockFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/bedrock_evaluate_answer_completeness_accuracy_for_given_questions.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huggingface Evaluate Answer Completeness Accuracy for Given Questions</th>\n",
       "      <td>This notebook uses Huggingface model to evaluate the completeness and accuracy of answers for given questions. It provides a comprehensive analysis of the model's performance in understanding and answering questions.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformHuggingFaceFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/huggingface_evaluate_answer_completeness_accuracy_for_given_questions.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDF Extraction and Text Cleaning with Uniflow</th>\n",
       "      <td>This notebook demonstrates how to use uniflow for PDF extraction and text cleaning, including data clustering for further analysis. It provides a step-by-step guide for processing PDF data and preparing it for clustering.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_s3_txt.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDF Extraction and Text Cleaning with Data Clustering</th>\n",
       "      <td>This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis. It provides a comprehensive pipeline for preprocessing PDF data and preparing it for downstream tasks.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_pdf_extract_transform.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline Web Summary</th>\n",
       "      <td>This notebook demonstrates the use of uniflow for PDF extraction, text cleaning, and data clustering to generate a summary of web content. It showcases the end-to-end pipeline for web content analysis using uniflow.</td>\n",
       "      <td>PDF, HTML</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_web_summary.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDF Extraction and Text Cleaning with Data Clustering</th>\n",
       "      <td>This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_pdf.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLM Based PDF Extraction, Text Cleaning, Data Clustering</th>\n",
       "      <td>This notebook demonstrates the use of LLM for PDF extraction, text cleaning, and data clustering. It showcases the end-to-end workflow of processing PDF documents, cleaning the text data, and clustering similar documents based on their content.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLLMFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/vector_database/setup_resources.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extract PDF with Recursive Splitter</th>\n",
       "      <td>This notebook demonstrates how to use uniflow to extract text from PDF files using a recursive splitter, and then clean the extracted text data. It also showcases data clustering techniques to organize the extracted text data.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_pdf_with_recursive_splitter.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extract HTML</th>\n",
       "      <td>This notebook demonstrates how to use uniflow to extract text from HTML documents and clean the extracted text for data clustering. It also provides examples of using LLM-based PDF extraction for text cleaning.</td>\n",
       "      <td>HTML</td>\n",
       "      <td>TransformLLMFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_html.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extracting Text from PDF and Cleaning Data for Clustering</th>\n",
       "      <td>This notebook demonstrates how to use uniflow to extract text from PDF and clean the data for clustering. It includes preprocessing steps such as text extraction, data cleaning, and feature engineering.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_md.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extract PDF Nougat QA</th>\n",
       "      <td>This notebook demonstrates the process of extracting text from PDF documents using uniflow's LLM-based PDF extraction and performing data cleaning and clustering for QA purposes.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>LLM-based PDF Extraction</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_pdf_nougat_qa.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extract Text from PDF</th>\n",
       "      <td>This notebook demonstrates how to use uniflow to extract text from PDF documents, clean the extracted text, and perform data clustering for further analysis.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_txt.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extract Text from PDF and Clean</th>\n",
       "      <td>This notebook demonstrates how to extract text from PDF files and clean the extracted text for further processing. It includes techniques for handling special characters, removing noise, and normalizing the text data.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_txt_from_s3.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDF Extraction and Text Cleaning with Data Clustering</th>\n",
       "      <td>This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformLMQGFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_html_QA.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Question Answering with OpenAI GPT-3 on HTML Data</th>\n",
       "      <td>Using OpenAI GPT-3 model, this notebook performs question answering on HTML data, demonstrating the capability of the model to understand and respond to questions based on the provided HTML content.</td>\n",
       "      <td>HTML</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_html_QA.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI PDF Source 10k Summary</th>\n",
       "      <td>This notebook demonstrates the use of uniflow for extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data. It provides a summary of 10k PDF documents using OpenAI model.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_pdf_source_10k_summary.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI Jupyter Notebook QA</th>\n",
       "      <td>This notebook demonstrates how to use uniflow to perform question answering on Jupyter notebooks using OpenAI's language model. It includes examples of extracting text from Jupyter notebooks, cleaning the text, and performing data clustering.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_jupyter_notebook_QA.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huggingface Model Benchmark Neuron</th>\n",
       "      <td>This notebook benchmarks the performance of a Huggingface model for text extraction and data clustering using uniflow. It compares the model's speed and accuracy with different input data.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformHuggingFaceFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/huggingface_model_benchmark_neuron.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDF Extraction and Text Cleaning with Uniflow</th>\n",
       "      <td>This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the text data for further analysis. It includes preprocessing steps such as text extraction, text cleaning, and data clustering.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformGoogleMultiModalModelFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/google_multimodal_model.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI PDF Source 10k QA</th>\n",
       "      <td>This notebook demonstrates the use of uniflow for extracting text from PDF documents, cleaning the text data, and clustering the data using OpenAI's language model. It also includes a question-answering task on the extracted text data.</td>\n",
       "      <td>PDF</td>\n",
       "      <td>TransformOpenAIFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_pdf_source_10k_QA.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huggingface Model Benchmark G5</th>\n",
       "      <td>This notebook benchmarks the performance of a Huggingface model G5 for text extraction and data clustering using uniflow. It compares the model's accuracy and efficiency in processing large datasets.</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>TransformHuggingFaceFlow</td>\n",
       "      <td>https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/huggingface_model_benchmark_g5.ipynb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                       summary  \\\n",
       "title                                                                                                                                                                                                                                                                                                                                            \n",
       "OpenAI Evaluate Answer Completeness Accuracy for Given Questions                                                   This notebook uses uniflow to evaluate the completeness and accuracy of answers for given questions using OpenAI model. It provides insights into the performance of the model in generating accurate and complete answers.   \n",
       "OpenAI Compare Generated Answers to Grounding Answer                                                                                                          This notebook compares the answers generated by OpenAI language model to a grounding answer for evaluation. It provides a method to assess the quality of the generated answers.   \n",
       "Bedrock Evaluate Answer Completeness Accuracy for Given Questions                                                This notebook uses uniflow to evaluate the completeness and accuracy of answers for given questions using the Bedrock model. It provides insights into the quality of answers and helps in identifying areas for improvement.   \n",
       "Huggingface Evaluate Answer Completeness Accuracy for Given Questions                                                 This notebook uses Huggingface model to evaluate the completeness and accuracy of answers for given questions. It provides a comprehensive analysis of the model's performance in understanding and answering questions.   \n",
       "PDF Extraction and Text Cleaning with Uniflow                                                                    This notebook demonstrates how to use uniflow for PDF extraction and text cleaning, including data clustering for further analysis. It provides a step-by-step guide for processing PDF data and preparing it for clustering.   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                  This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis. It provides a comprehensive pipeline for preprocessing PDF data and preparing it for downstream tasks.   \n",
       "Pipeline Web Summary                                                                                                   This notebook demonstrates the use of uniflow for PDF extraction, text cleaning, and data clustering to generate a summary of web content. It showcases the end-to-end pipeline for web content analysis using uniflow.   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                                                                                                         This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis.   \n",
       "LLM Based PDF Extraction, Text Cleaning, Data Clustering                                  This notebook demonstrates the use of LLM for PDF extraction, text cleaning, and data clustering. It showcases the end-to-end workflow of processing PDF documents, cleaning the text data, and clustering similar documents based on their content.   \n",
       "Extract PDF with Recursive Splitter                                                                         This notebook demonstrates how to use uniflow to extract text from PDF files using a recursive splitter, and then clean the extracted text data. It also showcases data clustering techniques to organize the extracted text data.   \n",
       "Extract HTML                                                                                                                This notebook demonstrates how to use uniflow to extract text from HTML documents and clean the extracted text for data clustering. It also provides examples of using LLM-based PDF extraction for text cleaning.   \n",
       "Extracting Text from PDF and Cleaning Data for Clustering                                                                           This notebook demonstrates how to use uniflow to extract text from PDF and clean the data for clustering. It includes preprocessing steps such as text extraction, data cleaning, and feature engineering.   \n",
       "Extract PDF Nougat QA                                                                                                                                       This notebook demonstrates the process of extracting text from PDF documents using uniflow's LLM-based PDF extraction and performing data cleaning and clustering for QA purposes.   \n",
       "Extract Text from PDF                                                                                                                                                            This notebook demonstrates how to use uniflow to extract text from PDF documents, clean the extracted text, and perform data clustering for further analysis.   \n",
       "Extract Text from PDF and Clean                                                                                      This notebook demonstrates how to extract text from PDF files and clean the extracted text for further processing. It includes techniques for handling special characters, removing noise, and normalizing the text data.   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                                                                                                         This notebook demonstrates the process of extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data for further analysis.   \n",
       "Question Answering with OpenAI GPT-3 on HTML Data                                                                                       Using OpenAI GPT-3 model, this notebook performs question answering on HTML data, demonstrating the capability of the model to understand and respond to questions based on the provided HTML content.   \n",
       "OpenAI PDF Source 10k Summary                                                                                               This notebook demonstrates the use of uniflow for extracting text from PDF documents, cleaning the text data, and clustering the cleaned text data. It provides a summary of 10k PDF documents using OpenAI model.   \n",
       "OpenAI Jupyter Notebook QA                                                                  This notebook demonstrates how to use uniflow to perform question answering on Jupyter notebooks using OpenAI's language model. It includes examples of extracting text from Jupyter notebooks, cleaning the text, and performing data clustering.   \n",
       "Huggingface Model Benchmark Neuron                                                                                                                This notebook benchmarks the performance of a Huggingface model for text extraction and data clustering using uniflow. It compares the model's speed and accuracy with different input data.   \n",
       "PDF Extraction and Text Cleaning with Uniflow                                                               This notebook demonstrates how to use uniflow for extracting text from PDF documents and cleaning the text data for further analysis. It includes preprocessing steps such as text extraction, text cleaning, and data clustering.   \n",
       "OpenAI PDF Source 10k QA                                                                           This notebook demonstrates the use of uniflow for extracting text from PDF documents, cleaning the text data, and clustering the data using OpenAI's language model. It also includes a question-answering task on the extracted text data.   \n",
       "Huggingface Model Benchmark G5                                                                                                         This notebook benchmarks the performance of a Huggingface model G5 for text extraction and data clustering using uniflow. It compares the model's accuracy and efficiency in processing large datasets.   \n",
       "\n",
       "                                                                        input_data_type  \\\n",
       "title                                                                                     \n",
       "OpenAI Evaluate Answer Completeness Accuracy for Given Questions       Jupyter Notebook   \n",
       "OpenAI Compare Generated Answers to Grounding Answer                   Jupyter Notebook   \n",
       "Bedrock Evaluate Answer Completeness Accuracy for Given Questions      Jupyter Notebook   \n",
       "Huggingface Evaluate Answer Completeness Accuracy for Given Questions  Jupyter Notebook   \n",
       "PDF Extraction and Text Cleaning with Uniflow                                       PDF   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                               PDF   \n",
       "Pipeline Web Summary                                                          PDF, HTML   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                               PDF   \n",
       "LLM Based PDF Extraction, Text Cleaning, Data Clustering                            PDF   \n",
       "Extract PDF with Recursive Splitter                                                 PDF   \n",
       "Extract HTML                                                                       HTML   \n",
       "Extracting Text from PDF and Cleaning Data for Clustering                           PDF   \n",
       "Extract PDF Nougat QA                                                               PDF   \n",
       "Extract Text from PDF                                                               PDF   \n",
       "Extract Text from PDF and Clean                                                     PDF   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                               PDF   \n",
       "Question Answering with OpenAI GPT-3 on HTML Data                                  HTML   \n",
       "OpenAI PDF Source 10k Summary                                                       PDF   \n",
       "OpenAI Jupyter Notebook QA                                             Jupyter Notebook   \n",
       "Huggingface Model Benchmark Neuron                                     Jupyter Notebook   \n",
       "PDF Extraction and Text Cleaning with Uniflow                                       PDF   \n",
       "OpenAI PDF Source 10k QA                                                            PDF   \n",
       "Huggingface Model Benchmark G5                                         Jupyter Notebook   \n",
       "\n",
       "                                                                                             uniflow_type  \\\n",
       "title                                                                                                       \n",
       "OpenAI Evaluate Answer Completeness Accuracy for Given Questions                      TransformOpenAIFlow   \n",
       "OpenAI Compare Generated Answers to Grounding Answer                                  TransformOpenAIFlow   \n",
       "Bedrock Evaluate Answer Completeness Accuracy for Given Questions                             BedrockFlow   \n",
       "Huggingface Evaluate Answer Completeness Accuracy for Given Questions            TransformHuggingFaceFlow   \n",
       "PDF Extraction and Text Cleaning with Uniflow                                           TransformLMQGFlow   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                   TransformLMQGFlow   \n",
       "Pipeline Web Summary                                                                    TransformLMQGFlow   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                   TransformLMQGFlow   \n",
       "LLM Based PDF Extraction, Text Cleaning, Data Clustering                                 TransformLLMFlow   \n",
       "Extract PDF with Recursive Splitter                                                     TransformLMQGFlow   \n",
       "Extract HTML                                                                             TransformLLMFlow   \n",
       "Extracting Text from PDF and Cleaning Data for Clustering                               TransformLMQGFlow   \n",
       "Extract PDF Nougat QA                                                            LLM-based PDF Extraction   \n",
       "Extract Text from PDF                                                                   TransformLMQGFlow   \n",
       "Extract Text from PDF and Clean                                                         TransformLMQGFlow   \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                   TransformLMQGFlow   \n",
       "Question Answering with OpenAI GPT-3 on HTML Data                                     TransformOpenAIFlow   \n",
       "OpenAI PDF Source 10k Summary                                                         TransformOpenAIFlow   \n",
       "OpenAI Jupyter Notebook QA                                                            TransformOpenAIFlow   \n",
       "Huggingface Model Benchmark Neuron                                               TransformHuggingFaceFlow   \n",
       "PDF Extraction and Text Cleaning with Uniflow                          TransformGoogleMultiModalModelFlow   \n",
       "OpenAI PDF Source 10k QA                                                              TransformOpenAIFlow   \n",
       "Huggingface Model Benchmark G5                                                   TransformHuggingFaceFlow   \n",
       "\n",
       "                                                                                                                                                                                                                                                                  url  \n",
       "title                                                                                                                                                                                                                                                                  \n",
       "OpenAI Evaluate Answer Completeness Accuracy for Given Questions            https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_evaluate_answer_completeness_accuracy_for_given_questions.ipynb  \n",
       "OpenAI Compare Generated Answers to Grounding Answer                                    https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/openai_compare_generated_answers_to_grounding_answer.ipynb  \n",
       "Bedrock Evaluate Answer Completeness Accuracy for Given Questions          https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/bedrock_evaluate_answer_completeness_accuracy_for_given_questions.ipynb  \n",
       "Huggingface Evaluate Answer Completeness Accuracy for Given Questions  https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/rater/huggingface_evaluate_answer_completeness_accuracy_for_given_questions.ipynb  \n",
       "PDF Extraction and Text Cleaning with Uniflow                                                                             https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_s3_txt.ipynb  \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                                      https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_pdf_extract_transform.ipynb  \n",
       "Pipeline Web Summary                                                                                                 https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_web_summary.ipynb  \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                                                        https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/pipeline/pipeline_pdf.ipynb  \n",
       "LLM Based PDF Extraction, Text Cleaning, Data Clustering                                                           https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/vector_database/setup_resources.ipynb  \n",
       "Extract PDF with Recursive Splitter                                                                    https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_pdf_with_recursive_splitter.ipynb  \n",
       "Extract HTML                                                                                                                  https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_html.ipynb  \n",
       "Extracting Text from PDF and Cleaning Data for Clustering                                                                       https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_md.ipynb  \n",
       "Extract PDF Nougat QA                                                                                                https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_pdf_nougat_qa.ipynb  \n",
       "Extract Text from PDF                                                                                                          https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_txt.ipynb  \n",
       "Extract Text from PDF and Clean                                                                                        https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/extract/extract_txt_from_s3.ipynb  \n",
       "PDF Extraction and Text Cleaning with Data Clustering                                                                     https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_html_QA.ipynb  \n",
       "Question Answering with OpenAI GPT-3 on HTML Data                                                                         https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_html_QA.ipynb  \n",
       "OpenAI PDF Source 10k Summary                                                                              https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_pdf_source_10k_summary.ipynb  \n",
       "OpenAI Jupyter Notebook QA                                                                                    https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_jupyter_notebook_QA.ipynb  \n",
       "Huggingface Model Benchmark Neuron                                                                    https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/huggingface_model_benchmark_neuron.ipynb  \n",
       "PDF Extraction and Text Cleaning with Uniflow                                                                    https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/google_multimodal_model.ipynb  \n",
       "OpenAI PDF Source 10k QA                                                                                        https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/openai_pdf_source_10k_QA.ipynb  \n",
       "Huggingface Model Benchmark G5                                                                            https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering/tree/main/example/transform/huggingface_model_benchmark_g5.ipynb  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where the 'url' column does not start with the specified prefix\n",
    "df_filtered = df[df['url'].str.startswith(home_url)]\n",
    "print(df_filtered.shape)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to markdown\n",
    "\n",
    "Now we can save the dataframe to a markdown file and use it in the README file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the markdown text to a .md file\n",
    "df_markdown = df_filtered.to_markdown(index=True)\n",
    "file_path = 'toc_examples.md'\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(df_markdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the notebook\n",
    "\n",
    "Check more Uniflow use cases in the [example folder](https://github.com/CambioML/uniflow/tree/main/example/model#examples)!\n",
    "\n",
    "<a href=\"https://www.cambioml.com/\" title=\"Title\">\n",
    "    <img src=\"./image/cambioml_logo_large.png\" style=\"height: 100px; display: block; margin-left: auto; margin-right: auto;\"/>\n",
    "</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
