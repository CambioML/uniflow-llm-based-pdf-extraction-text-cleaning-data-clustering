{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cbc4c4a",
   "metadata": {},
   "source": [
    "# Example of generating QAs for an ML book (using self-instruct)\n",
    "Source: https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/information-theory.html\n",
    "\n",
    "### Before running the code\n",
    "\n",
    "You will need to have the following packages installed:\n",
    "```\n",
    "pip install langchain pandas unstructured\n",
    "```\n",
    "\n",
    "Also, make sure you have a .env file with your OpenAI API key in the root directory of this project.\n",
    "```\n",
    "OPENAI_API_KEY=YOUR_API_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d84dd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joseortiz/anaconda3/envs/uniflow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from uniflow.client import Client\n",
    "from uniflow.config import OpenAIJsonConfig\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from uniflow.schema import Context, GuidedPrompt\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb677037",
   "metadata": {},
   "source": [
    "## Prepare the input data\n",
    "\n",
    "Uncomment any of the html files below as the sample file to build the self-instruct flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a707ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#html_file = \"do_things_that_dont_scale.html\" #from http://paulgraham.com/ds.html\n",
    "#html_file = \"makers_schedule_managers_schedule.html\" #from http://www.paulgraham.com/makersschedule.html\n",
    "#html_file = \"life_is_short.html\" #http://www.paulgraham.com/vb.html\n",
    "html_file = \"22.11_information-theory.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b177df1",
   "metadata": {},
   "source": [
    "Set current directory and input data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "092b355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_cur = os.getcwd()\n",
    "input_file = os.path.join(f\"{dir_cur}/data/raw_input/\", html_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(input_file)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_prompt = GuidedPrompt(\n",
    "        instruction=\"Generate one question and its corresponding answer based on context. Following the format of the examples below to include the same context, question, and answer in the response.\",\n",
    "        examples=[\n",
    "            Context(\n",
    "                context=\"In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.\",\n",
    "                question=\"Who published A Mathematical Theory of Communication in 1948?\",\n",
    "                answer=\"Claude E. Shannon.\",\n",
    "            )\n",
    "        ]\n",
    ")\n",
    "\n",
    "data = [ Context(context=p) for p in pages[2].page_content.split(\"\\n\\n\") if len(p) > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(context='Any notion of information we develop must conform to this intuition.\\nIndeed, in the next sections we will learn how to compute that these\\nevents have \\\\(0\\\\textrm{ bits}\\\\), \\\\(2\\\\textrm{ bits}\\\\),\\n\\\\(~5.7\\\\textrm{ bits}\\\\), and \\\\(~225.6\\\\textrm{ bits}\\\\) of\\ninformation respectively.'),\n",
       " Context(context='If we read through these thought experiments, we see a natural idea. As\\na starting point, rather than caring about the knowledge, we may build\\noff the idea that information represents the degree of surprise or the\\nabstract possibility of the event. For example, if we want to describe\\nan unusual event, we need a lot information. For a common event, we may\\nnot need much information.'),\n",
       " Context(context='In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[-3:]\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ModelFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OpenAIJsonConfig(guided_prompt_template=guided_prompt)\n",
    "client = Client(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "output = client.run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'output': [{'response': [{'context': 'Any notion of information we develop must conform to this intuition. Indeed, in the next sections we will learn how to compute that these events have \\\\(0\\\\textrm{ bits}\\\\), \\\\(2\\\\textrm{ bits}\\\\), \\\\(~5.7\\\\textrm{ bits}\\\\), and \\\\(~225.6\\\\textrm{ bits}\\\\) of information respectively.',\n",
       "      'question': 'What will we learn to compute in the next sections?',\n",
       "      'answer': 'The amount of information that different events have.'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x176ad4af0>},\n",
       " {'output': [{'response': [{'context': 'If we read through these thought experiments, we see a natural idea. As\\na starting point, rather than caring about the knowledge, we may build\\noff the idea that information represents the degree of surprise or the\\nabstract possibility of the event. For example, if we want to describe\\nan unusual event, we need a lot of information. For a common event, we may\\nnot need much information.',\n",
       "      'question': 'What does information represent according to the natural idea presented in the thought experiments?',\n",
       "      'answer': 'Information represents the degree of surprise or the abstract possibility of the event.'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x176ad4ac0>},\n",
       " {'output': [{'response': [{'context': 'In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.',\n",
       "      'question': 'What did Shannon introduce for the first time in his 1948 article?',\n",
       "      'answer': 'Shannon introduced the concept of information entropy for the first time.'}],\n",
       "    'error': 'No errors.'}],\n",
       "  'root': <uniflow.node.node.Node at 0x176ad4d00>}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format result into pandas table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Any notion of information we develop must conform to this intuition. Indeed, in the next sections we will learn how to compute that these events have \\(0\\textrm{ bits}\\), \\(2\\textrm{ bits}\\), \\(~5.7\\textrm{ bits}\\), and \\(~225.6\\textrm{ bits}\\) of information respectively.</td>\n",
       "      <td>What will we learn to compute in the next sections?</td>\n",
       "      <td>The amount of information that different events have.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If we read through these thought experiments, we see a natural idea. As\\na starting point, rather than caring about the knowledge, we may build\\noff the idea that information represents the degree of surprise or the\\nabstract possibility of the event. For example, if we want to describe\\nan unusual event, we need a lot of information. For a common event, we may\\nnot need much information.</td>\n",
       "      <td>What does information represent according to the natural idea presented in the thought experiments?</td>\n",
       "      <td>Information represents the degree of surprise or the abstract possibility of the event.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.</td>\n",
       "      <td>What did Shannon introduce for the first time in his 1948 article?</td>\n",
       "      <td>Shannon introduced the concept of information entropy for the first time.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                   context                                                                                             question                                                                                   answer\n",
       "0                                                                                                                        Any notion of information we develop must conform to this intuition. Indeed, in the next sections we will learn how to compute that these events have \\(0\\textrm{ bits}\\), \\(2\\textrm{ bits}\\), \\(~5.7\\textrm{ bits}\\), and \\(~225.6\\textrm{ bits}\\) of information respectively.                                                  What will we learn to compute in the next sections?                                    The amount of information that different events have.\n",
       "1  If we read through these thought experiments, we see a natural idea. As\\na starting point, rather than caring about the knowledge, we may build\\noff the idea that information represents the degree of surprise or the\\nabstract possibility of the event. For example, if we want to describe\\nan unusual event, we need a lot of information. For a common event, we may\\nnot need much information.  What does information represent according to the natural idea presented in the thought experiments?  Information represents the degree of surprise or the abstract possibility of the event.\n",
       "2                                                                                                                                         In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.                                   What did Shannon introduce for the first time in his 1948 article?                Shannon introduced the concept of information entropy for the first time."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting context, question, and answer into a DataFrame\n",
    "contexts = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for item in output:\n",
    "    for i in item['output']:\n",
    "        for response in i['response']:\n",
    "            contexts.append(response['context'])\n",
    "            questions.append(response['question'])\n",
    "            answers.append(response['answer'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'context': contexts,\n",
    "    'question': questions,\n",
    "    'answer': answers\n",
    "})\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_colwidth', None)  # or use a specific width like 50\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-instruct-ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
