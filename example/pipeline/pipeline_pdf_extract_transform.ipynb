{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of pipeline: extracting and transforming pdf file\n",
    "\n",
    "In this example, we will show you how use uniflow to extract and transform knowledge from a unstructured pdf file.\n",
    "\n",
    "Specifically, we will show you how to end-to-end generate question-answers (QAs) from a given pdf using uniflow's `MultiFlowsPipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before running the code\n",
    "\n",
    "You will need to `uniflow` conda environment to run this notebook. You can set up the environment following the instruction: https://github.com/CambioML/uniflow/tree/main#installation.\n",
    "\n",
    "### Update system path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install -q transformers accelerate bitsandbytes scipy nougat-ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/uniflow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from uniflow.pipeline import MultiFlowsPipeline\n",
    "from uniflow.flow.config import PipelineConfig\n",
    "from uniflow.flow.config import TransformHuggingFaceConfig, ExtractPDFConfig\n",
    "from uniflow.op.model.model_config import HuggingfaceModelConfig, NougatModelConfig\n",
    "from uniflow.op.prompt import PromptTemplate, Context\n",
    "from uniflow.op.extract.split.constants import MARKDOWN_HEADER_SPLITTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the input data\n",
    "\n",
    "First, let's set current directory and input data directory, and load the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_cur = os.getcwd()\n",
    "pdf_file = \"nike-paper.pdf\"\n",
    "input_file = os.path.join(f\"{dir_cur}/data/raw_input/\", pdf_file)\n",
    "\n",
    "data = [\n",
    "    {\"pdf\": input_file},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define extract config using Nougat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_config = ExtractPDFConfig(\n",
    "    model_config=NougatModelConfig(\n",
    "        model_name = \"0.1.0-small\",\n",
    "        batch_size = 1 # When batch_size>1, nougat will run on CUDA, otherwise it will run on CPU\n",
    "    ),\n",
    "    splitter=MARKDOWN_HEADER_SPLITTER\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare sample prompts\n",
    "\n",
    "Now we need to write a little bit prompts to generate question and answer for a given paragraph, each promopt data includes a instruction and a list of examples with \"context\", \"question\" and \"answer\". We do this by giving a sample list of `Context` examples to the `GuidedPrompt` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_prompt = PromptTemplate(\n",
    "    instruction=\"\"\"Generate one question and its corresponding answer based on the last context in the last\n",
    "    example. Follow the format of the examples below to include context, question, and answer in the response\"\"\",\n",
    "    few_shot_prompt=[\n",
    "        Context(\n",
    "            context=\"In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.\",\n",
    "            question=\"Who published A Mathematical Theory of Communication in 1948?\",\n",
    "            answer=\"Claude E. Shannon.\",\n",
    "        ),\n",
    "        \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define transform config\n",
    "\n",
    "In this example, we will use the [HuggingfaceModelConfig](https://github.com/CambioML/uniflow/blob/main/uniflow/model/config.py#L39)'s default LLM to generate questions and answers. Let's import the config of this model.\n",
    "\n",
    "Here, we pass in our `guided_prompt` to the `HuggingfaceConfig` to use our customized instructions and examples, instead of the `uniflow` default ones.\n",
    "\n",
    "Note, base on your GPU memory, you can set your optimal `batch_size` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1\n"
     ]
    }
   ],
   "source": [
    "current_batch_size = 1\n",
    "print(\"batch size:\", current_batch_size)\n",
    "\n",
    "transform_config = TransformHuggingFaceConfig(\n",
    "    prompt_template=guided_prompt,\n",
    "    model_config=HuggingfaceModelConfig(batch_size=current_batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use MultiFlowsPipeline\n",
    "\n",
    "Let's import the `PipelineConfig` of `MultiFlowsPipeline` to connect `extract_config` and `transform_config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/uniflow/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "p = MultiFlowsPipeline(PipelineConfig(\n",
    "    extract_config=extract_config,\n",
    "    transform_config=transform_config,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call the `run` method on the `MultiFlowsPipeline` object to execute the question-answer generation operation on the data shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:42<00:00, 42.38s/it]\n",
      " 77%|███████▋  | 10/13 [06:04<02:48, 56.25s/it]/home/ubuntu/anaconda3/envs/uniflow/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 13/13 [07:19<00:00, 33.78s/it]\n"
     ]
    }
   ],
   "source": [
    "output = p.run(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "Let's take a look of the generated output of Abstract segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the output\n",
    "\n",
    "Let's take a look of the generated output. We need to do a little postprocessing on the raw output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_18ad4 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_18ad4_row0_col0, #T_18ad4_row0_col1, #T_18ad4_row0_col2, #T_18ad4_row1_col0, #T_18ad4_row1_col1, #T_18ad4_row1_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_18ad4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_18ad4_level0_col0\" class=\"col_heading level0 col0\" >Context</th>\n",
       "      <th id=\"T_18ad4_level0_col1\" class=\"col_heading level0 col1\" >Question</th>\n",
       "      <th id=\"T_18ad4_level0_col2\" class=\"col_heading level0 col2\" >Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_18ad4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_18ad4_row0_col0\" class=\"data row0 col0\" > ## 2 Study Design\n",
       "We selected athletes who recorded a sufficiently fast marathon time--men under 2:24 and women under 2:45--at a collection of 22 distinct marathon venues in 2015 or 2016, including the 2016 U.S. Olympic Marathon Trials, which were contested in Los Angeles in February of 2016. The list of marathons is included in the Appendix. This resulted in a sample of 270 distinct women and 308 distinct men after matching names and our best effort to correct alternate spellings of names. We recorded these athletes' performances in the same 22 marathon venues over the period 2015 to 2019, and searched publicly available online photographs, manually identifying whether or not each athlete was wearing a Nike Vaporfly shoe by visual inspection. All marathon times were downloaded from the website www.marathonguide.com.\n",
       "Our criteria for inclusion in the study were meant to satisfy certain objectives. First, we wanted to study elite and sub-elite athletes, since shoe regulations are motivated by performance advantages for athletes in this group. Second, we wanted to study athletes who had achieved success in the marathon before the Nike Vaporfly shoes had been released to the public. This ensures that inclusion in the study is unrelated to whether an athlete was wearing the shoes in the race where they qualified for inclusion in the study. This is important because, if any shoe effect exists, the magnitude of the effect may differ among different athletes. If we were to use performances potentially aided by the shoes to select the athletes, that might have biased our sample towards athletes who benefit most from the shoes.\n",
       "To identify shoes worn by the runners, we used photos posted on public websites such as marathonfoto.com, marathon-photos.com, sportphoto.com, and flashframe.io. We also collected photographs from social media sites such as facebook.com and instagram.com. We assumed that Vaporfly shoes were not worn in 2015 or 2016 by any runners except for a few that were reported to have worn prototypes in the 2016 US Olympic Trials Marathon. Identification of shoes via photos is a manual process that is subject to error. We have made all of our shoe identifications publicly available at [https://github.com/joeguinness/vaporfly](https://github.com/joeguinness/vaporfly) and will update this paper with new data if we are made aware of any errors in shoe identification. We identified the shoes worn in 840 of 880 (95.5%) men's performances in our dataset and in 778 of 810 (96.0%) women's performances.\n",
       "</td>\n",
       "      <td id=\"T_18ad4_row0_col1\" class=\"data row0 col1\" > What were the criteria for inclusion in the study design?\n",
       "</td>\n",
       "      <td id=\"T_18ad4_row0_col2\" class=\"data row0 col2\" > The criteria for inclusion in the study design were to study elite and sub-elite athletes, and athletes who had achieved success in the marathon before the Nike Vaporfly shoes had been released to the public.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18ad4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_18ad4_row1_col0\" class=\"data row1 col0\" > ## 3 Data Exploration\n",
       "In Figure 1, we plot some summaries of the data. The left plot contains the proportion of runners wearing Vaporflys in each race in our dataset, separated by sex. Aside from a few prototypes being used in 2016, adoption of the shoes began in early 2017 and rose to over 50% on average in races at the end of 2019. The right plot contains the average marathon time for each athlete in the dataset in Vaporfly vs. non-Vaporfly shoes. Most runners' average time in Vaporfly shoes is faster than their average time in non-Vaporfly shoes. Specifically, 53 of 71 men (74.5%) who switched to Vaporflys ran faster in them, and 40 of 56 women (71.4%) who switched to Vaporflys ran faster in them.\n",
       "The right plot does not tell the whole story because it might be the case that runners who switched to Vaporflys did so when they ran on faster marathon courses. Some courses, such as the Boston Marathon course, have hills or often have poor weather, while others are flat and fast. So it is important to use the data to attempt to account for the difficulty of each\n",
       "Figure 1: (Left) Each circle represents an individual race, with the area of the circle proportional to the number of runners from the race in our dataset, and the vertical position equal to the proportion of runners wearing Vaporfly shoes in the race. (Right) Each circle represents an athlete, with the horizontal position being the athlete’s average marathon time in non-Vaporfly shoes, and the vertical position being the athlete’s average time in Vaporfly shoes.\n",
       "course. To get a satisfactory estimate of the effect of Vaporfly shoes, we need to analyze all of the data holistically, controlling for the strength of each runner and the difficulty of each marathon course. In the next section, we describe a statistical model intended for that purpose.\n",
       "</td>\n",
       "      <td id=\"T_18ad4_row1_col1\" class=\"data row1 col1\" > What is shown in the left plot of Figure 1?\n",
       "</td>\n",
       "      <td id=\"T_18ad4_row1_col2\" class=\"data row1 col2\" > The left plot of Figure 1 shows the proportion of runners wearing Vaporflys in each race in our dataset, separated by sex. It also indicates that adoption of the shoes began in early 2017 and rose to over 50% on average in races at the end of 2019.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbb095960b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting context, question, and answer into a DataFrame\n",
    "contexts = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "keywords = [\"context:\", \"question:\", \"answer:\"]\n",
    "pattern = '|'.join(map(re.escape, keywords))\n",
    "\n",
    "for item in output[0][3:5]:\n",
    "    o = item['output'][0]['response'][0]\n",
    "    segments = [segment for segment in re.split(pattern, o) if segment.strip()]\n",
    "\n",
    "    contexts.append(segments[-3])\n",
    "    questions.append(segments[-2])\n",
    "    answers.append(segments[-1])\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Context': contexts,\n",
    "    'Question': questions,\n",
    "    'Answer': answers\n",
    "})\n",
    "\n",
    "styled_df = df.style.set_properties(**{'text-align': 'left'}).set_table_styles([{\n",
    "    'selector': 'th',\n",
    "    'props': [('text-align', 'left')]\n",
    "}])\n",
    "styled_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
