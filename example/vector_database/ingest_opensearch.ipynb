{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `Uniflow` to Extract PDF and Ingest into OpenSearch\n",
    "\n",
    "### Before running the code\n",
    "\n",
    "You will need to create a `uniflow` conda environment to run this notebook. You can set up the environment following the instruction: https://github.com/CambioML/uniflow/tree/main#installation.\n",
    "\n",
    "Next, you will need a valid [AWS CLI profile](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html) to run the code. You can set up the profile by running `aws configure --profile <profile_name>` in your terminal. You will need to provide your AWS Access Key ID and AWS Secret Access Key. You can find your AWS Access Key ID and AWS Secret Access Key in the [Security Credentials](https://console.aws.amazon.com/iam/home?region=us-east-1#/security_credentials) section of the AWS console.\n",
    "\n",
    "```bash\n",
    "$ aws configure --profile <profile_name>\n",
    "$ AWS Access Key ID [None]: <your_access_key_id>\n",
    "$ AWS Secret Access Key [None]: <your_secret_access_key>\n",
    "$ Default region name [None]: us-west-2\n",
    "$ Default output format [None]: .json\n",
    "```\n",
    "\n",
    "Make sure to set `Default output format` to `.json`.\n",
    "\n",
    "> Note: If you don't have AWS CLI installed, you will get a `command not found: aws` error. You can follow the instructions [here](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run the code, you will need to set up the resources and environment variables in setup_resources.ipynb\n",
    "\n",
    "You can check the .env file to see if the environment variables are set up correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependency\n",
    "First, we set system paths and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/file_extraction/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "import warnings\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from uniflow.flow.client import ExtractClient\n",
    "from uniflow.flow.config import ExtractImageConfig\n",
    "from uniflow.op.model.model_config import LayoutModelConfig\n",
    "\n",
    "from utils.aws_session import AWSSession\n",
    "from utils.bedrock_client import BedrockEmbeddingClient\n",
    "from utils.es_client import ElasticSearchClient\n",
    "from utils.s3_client import S3Client\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Extra Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install -q boto3\n",
    "!{sys.executable} -m pip install -q easyocr\n",
    "!{sys.executable} -m pip install -q pdf2image\n",
    "!{sys.executable} -m pip install -q onnxruntime\n",
    "!{sys.executable} -m pip install -q pip install opensearch-py\n",
    "!{sys.executable} -m pip install -q onnxruntime-gpu\n",
    "!{sys.executable} -m pip install -q requests-aws4auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions\n",
    "In the following, we define some useful functions to help us convert PDF to images, and further extract text from images.\n",
    "\n",
    "The `convert_pdf_to_pngs` function converts a PDF file into a series of PNG images, with one image per page of the PDF. \n",
    "\n",
    "Here's a breakdown of the function parameters:\n",
    "\n",
    "- `pdf_file`: This is the path to the PDF file that you want to convert.\n",
    "- `dest_dir`: This is the directory where the PNG images will be saved.\n",
    "- `dpi`: This is the resolution in dots per inch. The default value is 200.\n",
    "- `fmt`: This is the format of the output images. The default value is \"png\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_pngs(pdf_file, dest_dir, dpi=200, fmt=\"png\"):\n",
    "    \"\"\"\n",
    "    Convert a PDF file to a directory of PNG images.\n",
    "    \"\"\"\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    images = convert_from_path(\n",
    "        pdf_file,\n",
    "        dpi=dpi,\n",
    "        output_folder=dest_dir,\n",
    "        fmt=fmt,\n",
    "        output_file=f\"{Path(pdf_file).stem}-\",\n",
    "    )\n",
    "\n",
    "    return dest_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `extract_image_pipeline` function is designed to extract text from an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_pipeline(local_file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from an image.\n",
    "\n",
    "    Args:\n",
    "        local_file_path (str): The path to the local image file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The extracted text from the image.\n",
    "    \"\"\"\n",
    "    data = [\n",
    "        {\"filename\": local_file_path},\n",
    "    ]\n",
    "\n",
    "    config = ExtractImageConfig(model_config=LayoutModelConfig())\n",
    "    layout_client = ExtractClient(config)\n",
    "    output = layout_client.run(data)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block is initializing several clients to interact with various AWS services.\n",
    "\n",
    "1. **AWSSession**: The `AWSSession` object is initialized with a dictionary containing the AWS profile name. The `session` attribute of this object is then accessed to create a session that can be used to authenticate with AWS services.\n",
    "\n",
    "2. **S3Client**: The `S3Client` object is initialized with the AWS session and a dictionary containing the AWS region. This client can be used to interact with the S3 service in the specified region.\n",
    "\n",
    "3. **ElasticSearchClient (OpenSearch Client)**: The `ElasticSearchClient` object is initialized with the AWS session and a dictionary containing the OpenSearch URL, AWS region, and OpenSearch username and password. These are fetched from environment variables. This client can be used to interact with the OpenSearch service.\n",
    "\n",
    "4. **BedrockEmbeddingClient**: The `BedrockEmbeddingClient` object is initialized with the AWS session and a dictionary containing the model ID and an empty dictionary for model kwargs. This client can be used to interact with the Bedrock service for embedding tasks.\n",
    "\n",
    "Each of these clients is used to interact with a different AWS service, and they are all authenticated using the same AWS session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_session = AWSSession(\n",
    "    {\n",
    "        \"aws_profile\": \"default\",\n",
    "    }\n",
    ").session\n",
    "custom_s3_client = S3Client(\n",
    "    aws_session,\n",
    "    {\n",
    "        \"aws_region\": \"us-west-2\",\n",
    "    },\n",
    ")\n",
    "opensearch_client = ElasticSearchClient(\n",
    "    aws_session,\n",
    "    {\n",
    "        \"opensearch_url\": os.getenv(\"OPENSEARCH_URL\"),\n",
    "        \"aws_region\": \"us-west-2\",\n",
    "        \"es_username\": os.getenv(\"ES_USERNAME\"),\n",
    "        \"es_password\": os.getenv(\"ES_PASSWORD\"),\n",
    "    },\n",
    ")\n",
    "bedrock_client = BedrockEmbeddingClient(\n",
    "    aws_session,\n",
    "    {\n",
    "        \"model_id\": \"amazon.titan-embed-text-v1\",\n",
    "        \"model_kwargs\": {},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 1: Ingest One file into OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step, we will download the PDF file from the S3 bucket and convert it into a series of PNG images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file from S3 to es_sample_files/pdf/nike-paper.pdf\n"
     ]
    }
   ],
   "source": [
    "s3_bucket = os.getenv(\"S3_BUCKET\")\n",
    "s3_prefix = os.getenv(\"S3_PREFIX\")\n",
    "\n",
    "sample_files_dir = \"es_sample_files\"\n",
    "pdf_dir = os.path.join(sample_files_dir, \"pdf\")\n",
    "local_file_path = custom_s3_client.download_file_from_s3(s3_bucket, s3_prefix, pdf_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we convert the file to a series of PNG images and upload them to the S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-14.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-06.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-09.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-13.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-12.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-05.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-01.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-10.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-04.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-03.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-07.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-08.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-11.png\n",
      "Uploading file to S3 from es_sample_files/png/nike-paper/nike-paper-0001-02.png\n"
     ]
    }
   ],
   "source": [
    "png_dir = os.path.join(sample_files_dir, \"png\", Path(local_file_path).stem)\n",
    "convert_pdf_to_pngs(local_file_path, png_dir)\n",
    "s3_png_prefix = os.path.join(\"uniflow-es-sample\", \"png\", Path(local_file_path).stem)\n",
    "s3_png_paths = custom_s3_client.upload_files_to_s3(s3_bucket, f\"{s3_png_prefix}/\", png_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we ingest the file into OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"uniflow-es-sample-index\"\n",
    "\n",
    "for file_id, file in enumerate(os.listdir(png_dir)):\n",
    "    data = []\n",
    "    local_png_path = os.path.join(png_dir, file)\n",
    "    extract_result = extract_image_pipeline(local_png_path)\n",
    "    texts = extract_result[0][\"output\"][0][\"text\"]\n",
    "    for text in texts:\n",
    "        print(text, local_png_path)\n",
    "        embedding = bedrock_client.get_text_embedding(text)\n",
    "        metadata = {\n",
    "            \"s3_path\": f\"s3://{s3_bucket}/{s3_png_prefix}/{file}\",\n",
    "            \"filename\": file,\n",
    "        }\n",
    "        one_page_data = {\n",
    "            \"id\": file_id,\n",
    "            \"metadata\": metadata,\n",
    "            \"text\": text,\n",
    "            \"vector_field\": embedding,\n",
    "        }\n",
    "        data.append(one_page_data)\n",
    "\n",
    "    # Step 4: Write the result to Amazon OpenSearch\n",
    "    opensearch_client.bulk_ingest_elasticsearch(index_name, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Ingestion\n",
    "After we finish the ingestion, we can test the ingestion by querying the OpenSearch index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniflow-es-sample-index\n",
      "klhAMo0B0g7dU03EYF6r\n",
      "0.8391172\n",
      "By collecting data on marathon times and identifying shoes WOrn in a systematic sample of elite and sub-elite marathon runners , we studied how much a runner s marathon time can be lexpected to improve after switching to Vaporfly shoes: For men the improvement is most likely somewhere between 2.0 and 3.9 minutes, o1' between 1.4% and 2.8%. For women it is likely between 0.8 and 3.5 minutes; or between 0.6% and 2.2%. To these numbers into perspective,elite marathon runners cover more than half a mile in 3 minutes. put\n",
      "nike-paper-0001-08.png\n",
      "uniflow-es-sample-index\n",
      "l1hAMo0B0g7dU03EYF6r\n",
      "0.8216595\n",
      "It is possible that athletes are more likely to switch to Vaporfly shoes when they know are ready to turn in marathon_performance Inversely some athletes might not be they good\n",
      "nike-paper-0001-08.png\n"
     ]
    }
   ],
   "source": [
    "embedding = bedrock_client.get_text_embedding(\n",
    "    \"How much a runner’s marathon time can be expected to improve after switching to Vaporfly shoes?\"\n",
    ")\n",
    "search_result = opensearch_client.knn_search(index_name, embedding)\n",
    "for hit in search_result:\n",
    "    print(hit[\"_index\"])\n",
    "    print(hit[\"_id\"])\n",
    "    print(hit[\"_score\"])\n",
    "    print(hit[\"_source\"][\"text\"])\n",
    "    print(hit[\"_source\"][\"metadata\"][\"filename\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the notebook\n",
    "\n",
    "Check more Uniflow use cases in the [example folder](https://github.com/CambioML/uniflow/tree/main/example/model#examples)!\n",
    "\n",
    "<a href=\"https://www.cambioml.com/\" title=\"Title\">\n",
    "    <img src=\"../image/cambioml_logo_large.png\" style=\"height: 100px; display: block; margin-left: auto; margin-right: auto;\"/>\n",
    "</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
